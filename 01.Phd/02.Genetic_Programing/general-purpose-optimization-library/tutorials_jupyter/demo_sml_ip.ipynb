{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arabic-absorption",
   "metadata": {},
   "source": [
    "# Solving supervised machine learning problems (from the perspective of inductive programming).\n",
    "Inductive program synthesis (aka inductive programming) is a subfield in the program synthesis that studies program generation from incomplete information, namely from the examples for the desired input/output behavior of the program. Genetic programming (GP) is one of the numerous approaches for the inductive synthesis characterized by performing the search in the space of syntactically correct programs of a given programming language.\n",
    "\n",
    "In the context of supervised machine learning (SML) problem-solving, one can define the task of a GP algorithm as the program/function induction from input/output examples that identifies the mapping $f:S\\mapsto R$ in the best possible way, generally measured through solution’s generalization ability on previously unseen data.\n",
    "\n",
    "## SML problem type.\n",
    "Given the definitions provided above and in order to make it possible to perform automatic induction of programs from the input/output-examples, we have conceptualized a module called ``inductive_programming`` which contains different problem types, materialized as classes. One of them, called ``SML``, a subclass of ``Problem``, aims at supporting the SML problem-solving (specifically the symbolic regression and binary classification by means of GP).\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/77/Genetic_Program_Tree.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-elephant",
   "metadata": {},
   "source": [
    "# 1. Create an instance of ``SML``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-pastor",
   "metadata": {},
   "source": [
    "Loads the necessary classes and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "binary-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports PyTorch\n",
    "import torch\n",
    "# Imports problems\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gpol.problems.inductive_programming import SML\n",
    "from gpol.utils.datasets import load_boston\n",
    "from gpol.utils.utils import train_test_split, rmse\n",
    "from gpol.utils.inductive_programming import function_map\n",
    "# Imports metaheuristics \n",
    "from gpol.algorithms.random_search import RandomSearch\n",
    "from gpol.algorithms.local_search import HillClimbing, SimulatedAnnealing\n",
    "from gpol.algorithms.genetic_algorithm import GeneticAlgorithm\n",
    "# Imports operators\n",
    "from gpol.operators.initializers import rhh, prm_full, grow\n",
    "from gpol.operators.selectors import prm_tournament\n",
    "from gpol.operators.variators import prm_subtree_mtn, swap_xo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-breath",
   "metadata": {},
   "source": [
    "Creates an instance of ``SML`` problem. The search space (*S*) of an instance of ``SML`` problem consists of the following key-value pairs:\n",
    "- ``\"n_dims\"`` is the number of input features (aka input dimensions) in the underlying ``SML`` problem's instance;\n",
    "- ``\"function set\"`` is the set of primitive functions;\n",
    "- ``\"constant set\"`` is the set of constants to draw terminals from;\n",
    "- ``\"p_constants\"`` is the probability of generating a constant when sampling a terminal;\n",
    "-  ``max_init_depth`` is the trees’ maximum depth during the initialization;\n",
    "-  ``max_depth`` is the trees’ maximum depth during the evolution; and\n",
    "-  ``n_batches`` is number of batches to use when evaluating solutions (more than one can be used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "informed-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the processing device and random state 's seed\n",
    "device, seed, p_test = 'cpu', 0, 0.3\n",
    "# Loads the data\n",
    "X, y = load_boston(X_y=True)\n",
    "# Defines parameters for the data usage\n",
    "batch_size, shuffle, p_test = 50, True, 0.3\n",
    "# Performs train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, p_test=p_test, seed=seed)\n",
    "# Creates training and test data sets\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "# Creates training and test data loaders\n",
    "dl_train = DataLoader(dataset=ds_train, batch_size=batch_size, shuffle=shuffle)\n",
    "dl_test = DataLoader(dataset=ds_test, batch_size=batch_size, shuffle=shuffle)\n",
    "# Characterizes the program elements: function and constant sets\n",
    "function_set = [function_map[\"add\"], function_map[\"sub\"], function_map[\"mul\"], function_map[\"div\"]]\n",
    "constant_set = torch.tensor([-1.0, -0.5, 0.5, 1.0], device=device)\n",
    "# Defines the search space\n",
    "sspace = {\"n_dims\": X.shape[1], \"function_set\": function_set, \"constant_set\": constant_set, \"p_constants\": 0.1, \n",
    "          \"max_init_depth\": 5, \"max_depth\": 15, \"n_batches\": 1}\n",
    "# Creates an instanec of SML\n",
    "pi = SML(sspace, rmse, dl_train, dl_test, min_=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-assembly",
   "metadata": {},
   "source": [
    "# 2. Choose and parametrize the algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-cathedral",
   "metadata": {},
   "source": [
    "## 2.1. Random search (RS).\n",
    "The random search (RS) can be seen as thethe first rudimentary stochastic metaheuristic for problem-solving. Its strategy, far away from being *intelligent*, consists of randomly sampling $S$ for a given number of iterations. As such, the only search-parameter of an instance of ``RandomSearch`` is the initialization function (the ``initializer``). The function ``grow`` stands for the Grow initialization technique and returns a single tree with maximum initial depth equal to ``max_init_depth``; the method assumes the probability of sampling a program element from the set of functions is the same as from the set of terminals until achieving the maximum depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-water",
   "metadata": {},
   "source": [
    "The cell in below creates a dictionary called ``pars`` which stores algorithms' parameters. Each key-value pair stores the algorithm's type and a dictionary of respective search-parameters. The first key-value pair regards the RS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "incorrect-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a single-point (SP) initializer\n",
    "sp_init = grow\n",
    "# Defines RS's parameters\n",
    "pars = {RandomSearch: {\"initializer\": sp_init}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-azerbaijan",
   "metadata": {},
   "source": [
    "## 2.2. Hill climbing (HC).\n",
    "The local search (LS) algorithms can be seen among the first intelligent search strategies that improve the functioning of the RS. They rely upon the concept of neighborhood which is explored at each iteration by sampling from $S$ a limited number of neighbors of the best-so-far solution. Usually, the LS algorithms are divided in two branches. In the first branch, called hill climbing (HC), or hill descent for the minimization problems, the best-so-far solution is replaced by its neighbor when the latter is at least as good as the former."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-raleigh",
   "metadata": {},
   "source": [
    "The cell in below adds ``HillClimbing`` to ``pars``. Note that, unlike it was for ``RandomSearch``, an instance of ``HillClimbing`` requires also the specification of a neighbor-generation function (``\"nh_function\"``) and the neighborhood's size (``\"nh_size\"``). Note that the very same initialization function is used for both ``RandomSearch`` and ``HillClimbing``. Also, ``\"nh_size\"`` equals ``pop_size`` to foster the equivalency between LS algorithms and Population-Based (PB); for the same reason, the parametrized neighbor-generation function is stored in a variable called ``mutator`` (details will be given in few sections below). \n",
    "\n",
    "The cell in below adds ``HillClimbing`` to ``pars``. Note that, unlike it was for ``RandomSearch``, an instance of ``HillClimbing`` also requires the specification of a neighbor-generation function (``\"nh_function\"``) and the neighborhood's size (``\"nh_size\"``). In this example, the so-called *subtree mutation* is used, an operator which replaces a random subtree in the individual by another, randomly generated tree; the latter is generated by means of Full initialization technique using the $S$ defined for the problem's instance (``initializer=prm_full(sspace)``). Note that the very same initialization function is used for both ``RandomSearch`` and ``HillClimbing``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "copyrighted-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the size of the population/neighborhood \n",
    "nh_size = 500\n",
    "# Defines neighbor-generation function with the respective parameters\n",
    "nh_function = prm_subtree_mtn(initializer=prm_full(sspace))\n",
    "# Defines HC's parameters\n",
    "pars[HillClimbing] = {\"initializer\": sp_init, \"nh_function\": nh_function, \"nh_size\": nh_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-sunrise",
   "metadata": {},
   "source": [
    "## 2.3. Simulated annealing (SA).\n",
    "The second branch, called simulated annealing (SA), extends HC by formulating a non-negative probability of replacing the best-so-far solution by its neighbor when the latter is worse. Traditionally, such a probability is small and decreases as the search advances. The strategy adopted by SA is especially useful when the search is prematurely tagnated at a locally sub-optimal point in $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-bicycle",
   "metadata": {},
   "source": [
    "The cell in below adds ``SimulatedAnnealing`` to ``pars``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "mineral-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines SA's parameters\n",
    "pars[SimulatedAnnealing] = {\"initializer\": sp_init, \"nh_function\": nh_function, \"nh_size\": nh_size, \"control\": 1.0, \"update_rate\": 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-drive",
   "metadata": {},
   "source": [
    "## 2.4. Genetic programming (GP) as genetic algorithm (GA).\n",
    "Based on the number of candidate solutions they handle at each step, the metaheuristics can be categorized into single-point (SP) and population-based (PB) approaches. \n",
    "The search procedure in the SP metaheuristics is generally guided by the information provided by a single candidate solution from $S$, usually the best-so-far solution, that is gradually evolved in a well-defined manner in hope to find the global optimum. The abovementioned HC and SA are examples of SP metaheuristics as the search is performed by exploring the neighborhood $N(i)$, where $i$ is the current best solution. Contrarily, the search procedure in PB metaheuristics is generally guided by the information shared by a set of candidate solutions and the exploitation of its collective behavior in different ways. In abstract terms, one can say that every PB metaheuristics shares, at least, the following two features: an object representing the set of simultaneously exploited candidate solutions (i.e., the population), and a procedure to *move* them across $S$.\n",
    "\n",
    "Genetic Algorithm (GAs) is a meta-heuristic introduced by J. Holland which was strongly inspired by Darwin's theory of evolution by means of natural selection. Conceptually, the algorithm starts with a random-like population of candidate solutions (called *chromosomes*). Then, by mimicking the natural selection and genetically inspired variation operators, such as the crossover and the mutation, the algorithm breeds a population of the next-generation candidate solutions (called the *offspring population*), that replaces the previous population (a.k.a. the *parent population*). This procedure is iterated until reaching some stopping criteria, like a maximum\n",
    "number of iterations (also called *generations*).\n",
    "\n",
    "Genetic programming (GP) is a PB metaheuristic, proposed and popularized by J. Koza, which extends GAs to allow the exploration of the space of computer programs. Similar to other evolutionary algorithms (EAs), GP evolves a set of candidate solutions (the population) by mimicking the basic principles of Darwinian evolution. The evolutionary process involves fitness-based selection of the candidate solutions and their variation by means of genetically-inspired operators (such as the crossover and the mutation). If abstracted from some implementation details, GP can be seen as\n",
    "GA, in which initialization and variation operators were specifically adjusted to work upon tree-based representations of candidate solutions (this idea was inspired by the LISP programming language, in which programs and data structures are represented as trees). Concretely, programs are defined using two sets: a set of primitive functions, which appear as the internal nodes of the trees, and a set of terminals, which represent the leaves of the trees. In the context of SML problem-solving, the trees represent mathematical expressions in the so-called Polish prefix notation, in which the operators (primitive functions) precede their operands (terminals). Given that the initialization, selection, and variation operators are provided as constructor parameters to solve a specific problem type, one can create an instance of GeneticAlgorithm to solve potentially any kind of problem, whether it is of continuous, combinatorial, or inductive program synthesis nature. The only two things one has to take into consideration are the correct specification of the problem-specific S and the operators. Following this perspective, by creating an instance of the class GeneticAlgorithm with, for example, ramped half-and-half (RHH) initialization, tournament selection, swap crossover and sub-tree mutation, all of them implemented in this library, one obtains a standard GP algorithm. Recall that a similar flexible behaviour is present in the branch of LS algorithms. By providing HC or SA with, for example, grow initialization and sub-tree mutation, one obtains a LS-based program induction algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-upgrade",
   "metadata": {},
   "source": [
    "The cell in below adds ``GeneticAlgorithm`` to ``pars``. It uses the Ramped Half-n-Half initialization (``rhh``), that returns a list of randomly generated trees. Note that the ``\"mutator\"`` key is assigned the very same function as the ``\"nh_function\"`` in the aforementioned LS algorithms, and the population's size is equivalent to neighborhood's size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "honest-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a population-based (PB) initializer\n",
    "pb_init = rhh\n",
    "# Defines GA's parameters\n",
    "pars[GeneticAlgorithm] = {\"pop_size\": nh_size, \"initializer\": pb_init, \"selector\": prm_tournament(pressure=0.1), \"mutator\": nh_function,\n",
    "                          \"crossover\": swap_xo, \"p_m\": 0.3, \"p_c\": 0.7, \"elitism\": True, \"reproduction\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-lloyd",
   "metadata": {},
   "source": [
    "# 3. Executes the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-quick",
   "metadata": {},
   "source": [
    "Note that *many* parameters and functions are shared across different algorithms in the experiment. This allows to increase the control and comparability between different algorithmic approaches when solving a given problem's instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "american-kenya",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gpol.algorithms.random_search.RandomSearch'>\n",
      "\t initializer <function grow at 0x0000023F77957430>\n",
      "<class 'gpol.algorithms.local_search.HillClimbing'>\n",
      "\t initializer <function grow at 0x0000023F77957430>\n",
      "\t nh_function <function prm_subtree_mtn.<locals>.subtree_mtn at 0x0000023F77B20820>\n",
      "\t nh_size 500\n",
      "<class 'gpol.algorithms.local_search.SimulatedAnnealing'>\n",
      "\t initializer <function grow at 0x0000023F77957430>\n",
      "\t nh_function <function prm_subtree_mtn.<locals>.subtree_mtn at 0x0000023F77B20820>\n",
      "\t nh_size 500\n",
      "\t control 1.0\n",
      "\t update_rate 0.9\n",
      "<class 'gpol.algorithms.genetic_algorithm.GeneticAlgorithm'>\n",
      "\t pop_size 500\n",
      "\t initializer <function rhh at 0x0000023F77957670>\n",
      "\t selector <function prm_tournament.<locals>.tournament at 0x0000023F77B20280>\n",
      "\t mutator <function prm_subtree_mtn.<locals>.subtree_mtn at 0x0000023F77B20820>\n",
      "\t crossover <function swap_xo at 0x0000023F779530D0>\n",
      "\t p_m 0.3\n",
      "\t p_c 0.7\n",
      "\t elitism True\n",
      "\t reproduction False\n"
     ]
    }
   ],
   "source": [
    "for isa_type, isa_pars in pars.items():\n",
    "    print(isa_type)\n",
    "    for p_name, p_val in isa_pars.items():\n",
    "        print(\"\\t\", p_name, p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-twins",
   "metadata": {},
   "source": [
    "Defines the computational resources for the experiment: the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fantastic-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-singer",
   "metadata": {},
   "source": [
    "Loops the afore-defined ``pars`` dictionary containing algorithms' and the underlying parameters. Note that besides algorithm-specific parameters, the constructor of an instance of a search algorithm also receives the random state to initialize a pseudorandom number generator (called ``seed``), and the specification of the processing ``device`` (either CPU or GPU).\n",
    "\n",
    "The ``solve`` method has the same signature for all the search algorithms and, in this example, includes the following parameters: \n",
    "-  ``n_iter``: number of iterations to conduct the search;\n",
    "-  ``tol``: minimum required fitness improvement for ``n_iter_tol`` consecutive iterations to continue the search. When the fitness is not improving by at least ``tol`` for ``n_iter_tol`` consecutive iterations, the search will be automatically interrupted;\n",
    "-  ``n_iter_tol``: maximum number of iterations to not meet ``tol`` improvement;\n",
    "-  ``verbose``: verbosity's detail-level;\n",
    "-  ``log``: log-files' detail-level (if exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "numerical-deputy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "           |                    Best solution                    |\n",
      "------------------------------------------------------------------\n",
      "Generation   Length   Fitness          Test Fitness         Timing\n",
      "0            7        32.4791          36.3134               0.005\n",
      "1            7        32.4791          35.7816               0.001\n",
      "2            7        32.4791          32.71                 0.001\n",
      "3            15       15.4184          14.1555               0.001\n",
      "4            15       15.4184          10.8436               0.001\n",
      "5            15       15.4184          13.3441               0.001\n",
      "6            15       15.4184          16.0714               0.001\n",
      "7            15       15.4184          13.7092               0.001\n",
      "8            15       15.4184          14.2241               0.001\n",
      "Algorithm: RandomSearch\n",
      "Best solution's fitness: 15.418\n",
      "Best solution: [mul, mul, tensor(1.), 4, sub, add, 1, sub, add, 8, 3, div, 10, tensor(-1.), 5]\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "           |                    Best solution                      |           Neighborhood           |\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Generation | Length   Fitness          Test Fitness         Timing | AVG Fitness           STD Fitness\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "0          | 7        32.4791          36.3134               0.003 | -1                             -1\n",
      "1          | 15       11.59            10.852                0.218 | 5.63832e+08           1.25974e+10\n",
      "2          | 11       6.19819          7.53713               0.243 | 2.04903e+06            3.3565e+07\n",
      "3          | 11       6.19819          9.1797                0.220 | 4.86283e+11           1.08696e+13\n",
      "4          | 11       6.19819          6.72299               0.263 | 2.58505e+06           4.81296e+07\n",
      "5          | 11       6.19819          8.11066               0.220 | 1.07256e+07           1.75361e+08\n",
      "6          | 9        5.92858          8.49589               0.238 | 8.25844e+07           1.83333e+09\n",
      "7          | 9        5.92858          5.63094               0.211 | 854312                1.40509e+07\n",
      "8          | 11       5.71802          8.77217               0.218 | 2.91308e+06           5.88267e+07\n",
      "9          | 11       5.71802          6.2566                0.244 | 1.05992e+09           1.88246e+10\n",
      "10         | 17       5.18237          8.4898                0.220 | 5.72367e+08           1.27789e+10\n",
      "11         | 17       5.18237          7.90475               0.244 | 2.68819e+06           5.36345e+07\n",
      "12         | 9        4.2145           6.38576               0.244 | 1.81567e+07           3.61118e+08\n",
      "13         | 9        4.2145           7.27925               0.227 | 2.78907e+07           5.78147e+08\n",
      "14         | 9        4.2145           8.41249               0.209 | 8.75457e+08           1.68607e+10\n",
      "15         | 9        4.2145           6.52375               0.201 | 4.47796e+07           8.81273e+08\n",
      "16         | 9        4.2145           6.32099               0.199 | 1.11e+09              2.47945e+10\n",
      "17         | 9        4.2145           8.02037               0.202 | 7.45179e+08           1.15931e+10\n",
      "Algorithm: HillClimbing\n",
      "Best solution's fitness: 4.214\n",
      "Best solution: [sub, add, div, 5, 4, 5, mul, 5, tensor(-0.5000)]\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "           |                    Best solution                      |           Neighborhood           |\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Generation | Length   Fitness          Test Fitness         Timing | AVG Fitness           STD Fitness\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "0          | 7        32.4791          36.3134               0.002 | -1                             -1\n",
      "1          | 15       11.59            10.852                0.202 | 5.63832e+08           1.25974e+10\n",
      "2          | 11       6.19819          7.53713               0.242 | 2.04903e+06            3.3565e+07\n",
      "3          | 13       8.09299          8.75443               0.228 | 4.86283e+11           1.08696e+13\n",
      "4          | 15       6.26685          4.79141               0.257 | 3.36168e+08            7.4902e+09\n",
      "5          | 15       5.6967           5.86967               0.241 | 2.52923e+07           4.25113e+08\n",
      "6          | 15       5.45817          6.60994               0.234 | 8.25749e+07           1.83333e+09\n",
      "7          | 15       5.45817          4.8867                0.253 | 44669                      468006\n",
      "8          | 13       5.0834           6.82529               0.232 | 127522                2.02334e+06\n",
      "9          | 13       5.0834           4.95445               0.246 | 1.05986e+09           1.88246e+10\n",
      "10         | 19       4.25923          8.568                 0.220 | 5.72468e+08           1.27789e+10\n",
      "11         | 19       4.69322          7.15276               0.262 | 2.82693e+06           5.38302e+07\n",
      "12         | 33       3.53963          5.829                 0.260 | 2.8499e+07            5.87694e+08\n",
      "13         | 33       4.53495          7.06472               0.355 | 773194                1.01506e+07\n",
      "14         | 33       4.10945          6.51063               0.339 | 7.43525e+08           1.66185e+10\n",
      "15         | 33       4.10945          5.19357               0.371 | 4.24536e+06            9.4408e+07\n",
      "16         | 33       4.10945          5.22135               0.337 | 204623                3.35911e+06\n",
      "17         | 33       4.10945          6.15177               0.335 | 4.32152e+08           9.30744e+09\n",
      "Algorithm: SimulatedAnnealing\n",
      "Best solution's fitness: 3.540\n",
      "Best solution: [sub, add, div, 5, 4, div, 10, mul, 4, 12, sub, add, div, tensor(1.), mul, mul, div, tensor(-1.), 11, mul, 9, 12, add, sub, 1, tensor(-0.5000), div, tensor(-0.5000), 10, mul, 4, 7, 5]\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "           |                    Best solution                      |            Population            |\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Generation | Length   Fitness          Test Fitness         Timing | AVG Fitness           STD Fitness\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "0          | 3        11.8392          10.4172               0.107 | 1.10298e+10           2.36261e+11\n",
      "1          | 15       10.563           13.1621               0.100 | 192734                3.00088e+06\n",
      "2          | 11       9.16125          9.14002               0.124 | 291416                5.78805e+06\n",
      "3          | 5        8.11863          7.72903               0.145 | 5841.34                   66659.1\n",
      "4          | 5        8.11863          9.1051                0.164 | 6369.21                    128032\n",
      "5          | 37       6.98226          6.9465                0.200 | 2.95148e+17           1.62494e+18\n",
      "6          | 37       6.98226          7.2005                0.220 | 6.64083e+17           2.38652e+18\n",
      "7          | 37       6.87697          7.01372               0.253 | 6.45636e+17           2.35567e+18\n",
      "8          | 37       6.87697          8.01412               0.352 | 7.9321e+17            2.58849e+18\n",
      "9          | 37       6.87697          6.13337               0.298 | 5.71849e+17           2.22649e+18\n",
      "10         | 53       5.84827          8.43751               0.308 | 3.13595e+17           1.67322e+18\n",
      "11         | 53       5.84827          7.83105               0.313 | 3.50488e+17           1.76524e+18\n",
      "12         | 65       5.25427          5.9743                0.317 | 4.98062e+17           2.08673e+18\n",
      "13         | 65       5.25427          5.45907               0.375 | 6.8253e+17            2.41683e+18\n",
      "14         | 65       5.25427          5.70832               0.409 | 2.76701e+17           1.57497e+18\n",
      "15         | 65       5.25427          6.42268               0.497 | 4.98062e+17           2.08673e+18\n",
      "16         | 65       5.25427          6.71437               0.600 | 7.00976e+17           2.44662e+18\n",
      "17         | 65       5.25427          6.06641               0.520 | 7.3787e+17            2.50474e+18\n",
      "Algorithm: GeneticAlgorithm\n",
      "Best solution's fitness: 5.254\n",
      "Best solution: [add, div, sub, add, 10, div, mul, 5, 11, add, 9, 4, sub, 12, add, add, sub, div, mul, 5, 11, add, 9, 4, sub, 12, 7, div, 6, 7, sub, add, add, sub, sub, 4, 12, sub, 12, 7, 10, sub, div, sub, 8, 4, mul, 8, 6, add, 8, 4, add, 8, 4, 12, add, 10, div, sub, 10, sub, 12, 7, 12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for isa_type, isa_pars in pars.items():\n",
    "    isa = isa_type(pi=pi, **isa_pars, seed=seed, device=device)\n",
    "    # n_iter*pop_size if isinstance(isa, RandomSearch) else n_iter  # equivalency for the RS\n",
    "    isa.solve(n_iter=n_iter, tol=0.1, n_iter_tol=5, test_elite=True, verbose=2, log=0)\n",
    "    print(\"Algorithm: {}\".format(isa_type.__name__))\n",
    "    print(\"Best solution's fitness: {:.3f}\".format(isa.best_sol.fit))\n",
    "    print(\"Best solution:\", isa.best_sol.repr_, end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
