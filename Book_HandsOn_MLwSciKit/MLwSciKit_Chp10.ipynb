{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 10 - Intro to Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows=500\n",
    "pd.options.display.max_columns=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12724/4105006777.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The scikit-learn version is {}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "\n",
    "print('The scikit-learn version is {}.'.format(statsmodels.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Single-TLU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)] #petal lengtg, petal width\n",
    "y = (iris.target == 0).astype(np.int) #Is Iris Setosa?\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor flow with pip installation check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classifier with Keras and Seq API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0 , X_train_full[5000:] / 255.0\n",
    "y_valid, y_train =  y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL sintax I:\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL sintax II:\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05895926, -0.00243484, -0.02156412, ...,  0.0299076 ,\n",
       "        -0.00690834,  0.05248143],\n",
       "       [-0.0368155 , -0.00768143, -0.01485808, ..., -0.00832687,\n",
       "         0.02034585,  0.00503024],\n",
       "       [-0.07075715,  0.03741304, -0.04308028, ..., -0.06714501,\n",
       "        -0.04244603,  0.06560196],\n",
       "       ...,\n",
       "       [-0.010499  , -0.00796263, -0.00645506, ...,  0.04714195,\n",
       "         0.03304257, -0.00901837],\n",
       "       [ 0.04357649, -0.02191432, -0.06987143, ...,  0.01001357,\n",
       "         0.00944569, -0.05962294],\n",
       "       [-0.06735739, -0.04182056,  0.06375726, ...,  0.04202609,\n",
       "        -0.05423624,  0.02752544]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer= 'sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 7s 3ms/step - loss: 0.7141 - accuracy: 0.7635 - val_loss: 0.5338 - val_accuracy: 0.8252\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4863 - accuracy: 0.8311 - val_loss: 0.4487 - val_accuracy: 0.8470\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4420 - accuracy: 0.8448 - val_loss: 0.4338 - val_accuracy: 0.8554\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4135 - accuracy: 0.8545 - val_loss: 0.3953 - val_accuracy: 0.8678\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3946 - accuracy: 0.8612 - val_loss: 0.3736 - val_accuracy: 0.8704\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3778 - accuracy: 0.8667 - val_loss: 0.3712 - val_accuracy: 0.8744\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3647 - accuracy: 0.8710 - val_loss: 0.3725 - val_accuracy: 0.8714\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3520 - accuracy: 0.8755 - val_loss: 0.3672 - val_accuracy: 0.8696\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3423 - accuracy: 0.8786 - val_loss: 0.3559 - val_accuracy: 0.8770\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3330 - accuracy: 0.8810 - val_loss: 0.3492 - val_accuracy: 0.8770\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3241 - accuracy: 0.8837 - val_loss: 0.3325 - val_accuracy: 0.8844\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3174 - accuracy: 0.8867 - val_loss: 0.3336 - val_accuracy: 0.8848\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3081 - accuracy: 0.8905 - val_loss: 0.3356 - val_accuracy: 0.8806\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3023 - accuracy: 0.8914 - val_loss: 0.3401 - val_accuracy: 0.8788\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2960 - accuracy: 0.8929 - val_loss: 0.3248 - val_accuracy: 0.8854\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2898 - accuracy: 0.8953 - val_loss: 0.3250 - val_accuracy: 0.8850\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2844 - accuracy: 0.8975 - val_loss: 0.3411 - val_accuracy: 0.8788\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2786 - accuracy: 0.8993 - val_loss: 0.3190 - val_accuracy: 0.8876\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2735 - accuracy: 0.9020 - val_loss: 0.3114 - val_accuracy: 0.8858\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2674 - accuracy: 0.9036 - val_loss: 0.3097 - val_accuracy: 0.8908\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2638 - accuracy: 0.9039 - val_loss: 0.3364 - val_accuracy: 0.8742\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2586 - accuracy: 0.9073 - val_loss: 0.3078 - val_accuracy: 0.8908\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2534 - accuracy: 0.9089 - val_loss: 0.3186 - val_accuracy: 0.8868\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2504 - accuracy: 0.9099 - val_loss: 0.3080 - val_accuracy: 0.8928\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2457 - accuracy: 0.9110 - val_loss: 0.3007 - val_accuracy: 0.8900\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2413 - accuracy: 0.9126 - val_loss: 0.3035 - val_accuracy: 0.8884\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2371 - accuracy: 0.9145 - val_loss: 0.3240 - val_accuracy: 0.8866\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2346 - accuracy: 0.9154 - val_loss: 0.3056 - val_accuracy: 0.8902\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2302 - accuracy: 0.9166 - val_loss: 0.2935 - val_accuracy: 0.8946\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2263 - accuracy: 0.9177 - val_loss: 0.3029 - val_accuracy: 0.8952\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 64.7007 - accuracy: 0.8551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[64.70066833496094, 0.8550999760627747]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Predictions:\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_x=np.argmax(y_proba,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[classes_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression MLP w/ Sequential Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#California Housing\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7890 - val_loss: 0.6164\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4712 - val_loss: 0.5091\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4368 - val_loss: 0.4829\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4418 - val_loss: 1.0516\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6639 - val_loss: 1.1859\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5392 - val_loss: 4.4548\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4527 - val_loss: 0.4097\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3972 - val_loss: 0.4107\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.3918\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.3876\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.3888\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3634 - val_loss: 0.3823\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3811\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.3804\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3567 - val_loss: 0.4021\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3571 - val_loss: 0.3755\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3536 - val_loss: 0.3782\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3571 - val_loss: 0.3765\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3716\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.3730\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3391\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Complex Models Using Keras API:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Widedeep Neural Network - Learn Complex patterns and simple rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of features to the simple path and anoher subset of features to de complex path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.8470 - val_loss: 1.0730\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8045 - val_loss: 0.7424\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6687 - val_loss: 0.6698\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6204 - val_loss: 0.6368\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5884 - val_loss: 0.6087\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5646 - val_loss: 0.5859\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5434 - val_loss: 0.5635\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5273 - val_loss: 0.5566\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5122 - val_loss: 0.5394\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4987 - val_loss: 0.5211\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4878 - val_loss: 0.5183\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4776 - val_loss: 0.5010\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4690 - val_loss: 0.4970\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4610 - val_loss: 0.4856\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4538 - val_loss: 0.4779\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4484 - val_loss: 0.4753\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4428 - val_loss: 0.4683\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4376 - val_loss: 0.4657\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4335 - val_loss: 0.4594\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4293 - val_loss: 0.4538\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4292\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Aux_output layer: When you want to solve 2 dif preditions based on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name= \"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the loss function of each output:\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.7268 - main_output_loss: 0.6602 - aux_output_loss: 1.3261 - val_loss: 0.5633 - val_main_output_loss: 0.5255 - val_aux_output_loss: 0.9037\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5321 - main_output_loss: 0.4967 - aux_output_loss: 0.8507 - val_loss: 1.4172 - val_main_output_loss: 1.4442 - val_aux_output_loss: 1.1746\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5729 - main_output_loss: 0.5494 - aux_output_loss: 0.7850 - val_loss: 0.4740 - val_main_output_loss: 0.4476 - val_aux_output_loss: 0.7120\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4413 - main_output_loss: 0.4163 - aux_output_loss: 0.6661 - val_loss: 0.4550 - val_main_output_loss: 0.4342 - val_aux_output_loss: 0.6421\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4273 - main_output_loss: 0.4054 - aux_output_loss: 0.6247 - val_loss: 0.4456 - val_main_output_loss: 0.4275 - val_aux_output_loss: 0.6082\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4235 - main_output_loss: 0.4053 - aux_output_loss: 0.5879 - val_loss: 0.4311 - val_main_output_loss: 0.4149 - val_aux_output_loss: 0.5768\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4059 - main_output_loss: 0.3878 - aux_output_loss: 0.5687 - val_loss: 0.4241 - val_main_output_loss: 0.4091 - val_aux_output_loss: 0.5595\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4007 - main_output_loss: 0.3835 - aux_output_loss: 0.5558 - val_loss: 0.4240 - val_main_output_loss: 0.4096 - val_aux_output_loss: 0.5534\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3930 - main_output_loss: 0.3760 - aux_output_loss: 0.5454 - val_loss: 0.4071 - val_main_output_loss: 0.3929 - val_aux_output_loss: 0.5350\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3926 - main_output_loss: 0.3767 - aux_output_loss: 0.5358 - val_loss: 0.4197 - val_main_output_loss: 0.4070 - val_aux_output_loss: 0.5334\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3866 - main_output_loss: 0.3708 - aux_output_loss: 0.5291 - val_loss: 0.4191 - val_main_output_loss: 0.4073 - val_aux_output_loss: 0.5260\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3800 - main_output_loss: 0.3647 - aux_output_loss: 0.5177 - val_loss: 0.4211 - val_main_output_loss: 0.4096 - val_aux_output_loss: 0.5245\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3841 - main_output_loss: 0.3695 - aux_output_loss: 0.5162 - val_loss: 0.3888 - val_main_output_loss: 0.3756 - val_aux_output_loss: 0.5069\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3737 - main_output_loss: 0.3590 - aux_output_loss: 0.5060 - val_loss: 0.4062 - val_main_output_loss: 0.3945 - val_aux_output_loss: 0.5121\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3716 - main_output_loss: 0.3572 - aux_output_loss: 0.5017 - val_loss: 0.3836 - val_main_output_loss: 0.3713 - val_aux_output_loss: 0.4942\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3817 - main_output_loss: 0.3678 - aux_output_loss: 0.5071 - val_loss: 0.3929 - val_main_output_loss: 0.3820 - val_aux_output_loss: 0.4912\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3687 - main_output_loss: 0.3553 - aux_output_loss: 0.4891 - val_loss: 0.3799 - val_main_output_loss: 0.3684 - val_aux_output_loss: 0.4841\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3649 - main_output_loss: 0.3515 - aux_output_loss: 0.4851 - val_loss: 0.3760 - val_main_output_loss: 0.3647 - val_aux_output_loss: 0.4775\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3591 - main_output_loss: 0.3458 - aux_output_loss: 0.4791 - val_loss: 0.3776 - val_main_output_loss: 0.3662 - val_aux_output_loss: 0.4794\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3578 - main_output_loss: 0.3446 - aux_output_loss: 0.4766 - val_loss: 0.3751 - val_main_output_loss: 0.3638 - val_aux_output_loss: 0.4768\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3620 - main_output_loss: 0.3482 - aux_output_loss: 0.4856\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2964537],\n",
       "       [1.6048795],\n",
       "       [2.557675 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3920918],\n",
       "       [1.3501427],\n",
       "       [2.2845201]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras API for Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    \n",
    "    def _init_(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super()._init_(**kwargs) #handles standard args\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layerDense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_A)\n",
    "        hidden2 = self.hidden2(input_B)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "model.save(\"my_keras_models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_models.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3934\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5054\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8536\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4085\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3811\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3863\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3697\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3644\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3594\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducing Early Stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3621 - val_loss: 0.3696\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3590 - val_loss: 0.3664\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3513 - val_loss: 0.3638\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3473 - val_loss: 0.3605\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3641\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3556\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3412 - val_loss: 0.3503\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3390 - val_loss: 0.3543\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3490\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3505\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # Roll back to the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3527\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3340 - val_loss: 0.3452\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3335 - val_loss: 0.3541\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3310 - val_loss: 0.3466\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3336 - val_loss: 0.3427\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3281 - val_loss: 0.3434\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3279 - val_loss: 0.3801\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3526\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3244 - val_loss: 0.3444\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3231 - val_loss: 0.3415\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3369\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3219 - val_loss: 0.3470\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3391\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3215 - val_loss: 0.3337\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3184 - val_loss: 0.3389\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3189 - val_loss: 0.3344\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3559\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3315 - val_loss: 0.3378\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3258 - val_loss: 0.4078\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4962 - val_loss: 0.3537\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3369 - val_loss: 0.3505\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3420\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.3393\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3249 - val_loss: 0.3365\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writting Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Board Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() #e.g. './my_logs/run_2021_11_11-9:23:32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3201 - val_loss: 0.3344\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3192 - val_loss: 0.3350\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3185 - val_loss: 0.3318\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3188 - val_loss: 0.3332\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3164 - val_loss: 0.3326\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3156 - val_loss: 0.3286\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3149 - val_loss: 0.3308\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3149 - val_loss: 0.3346\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3151 - val_loss: 0.3332\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3158 - val_loss: 0.3300\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3124 - val_loss: 0.3278\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3125 - val_loss: 0.3324\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3124 - val_loss: 0.3332\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3128 - val_loss: 0.3361\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3167 - val_loss: 0.3283\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3116 - val_loss: 0.3318\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3127 - val_loss: 0.3288\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3120 - val_loss: 0.3274\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3095 - val_loss: 0.3307\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3095 - val_loss: 0.3265\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3090 - val_loss: 0.3253\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3098 - val_loss: 0.3288\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.3373\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3120 - val_loss: 0.3350\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3122 - val_loss: 0.3230\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3101 - val_loss: 0.3233\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3083 - val_loss: 0.3311\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3367 - val_loss: 0.3307\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3085 - val_loss: 0.3250\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3073 - val_loss: 0.3204\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 +1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # Some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) #random 32x32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"its square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step = step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model - function to use GridSearchCV or RandomizedSearchCV in w/ Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4030 - val_loss: 0.9635\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7148 - val_loss: 0.6727\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5938 - val_loss: 0.6000\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5428 - val_loss: 0.5548\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5072 - val_loss: 0.5252\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4847 - val_loss: 0.5058\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4691 - val_loss: 0.4909\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4579 - val_loss: 0.4836\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.4704\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4412 - val_loss: 0.4643\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4341 - val_loss: 0.4604\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.4522\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.4467\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4191 - val_loss: 0.4418\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 0.4398\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4117 - val_loss: 0.4323\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4089 - val_loss: 0.4326\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4059 - val_loss: 0.4285\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4033 - val_loss: 0.4266\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.4227\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3988 - val_loss: 0.4198\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3965 - val_loss: 0.4183\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4170\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.4143\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3911 - val_loss: 0.4133\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.4124\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.4132\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3867 - val_loss: 0.4076\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.4070\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3842 - val_loss: 0.4035\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.4064\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3820 - val_loss: 0.4019\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3800 - val_loss: 0.4018\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.4019\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4000\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3776 - val_loss: 0.4006\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3772 - val_loss: 0.3982\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.3985\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.3940\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.4037\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3740 - val_loss: 0.3958\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.3993\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3918\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3717 - val_loss: 0.4061\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.3930\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3704 - val_loss: 0.3953\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.3878\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3901\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.3879\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3668 - val_loss: 0.3869\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.3847\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.3868\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3634 - val_loss: 0.3893\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3631 - val_loss: 0.3843\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.3858\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3615 - val_loss: 0.3841\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3845\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3607 - val_loss: 0.3829\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.3816\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3590 - val_loss: 0.3826\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3585 - val_loss: 0.3801\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3579 - val_loss: 0.3806\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3829\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3574 - val_loss: 0.3766\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3801\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3569 - val_loss: 0.3768\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3790\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3556 - val_loss: 0.3763\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3731\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3537 - val_loss: 0.3771\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3537 - val_loss: 0.3734\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3530 - val_loss: 0.3744\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3734\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3737\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3705\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3515 - val_loss: 0.3727\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.3712\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.3753\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3745\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3719\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.3871\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.3749\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3939\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3848\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.4053\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3494\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F6FF8DAF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data = (X_valid, y_valid),\n",
    "              callbacks = [early_stopping_cb])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam Tunning Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0782 - val_loss: 2.4818\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1677 - val_loss: 0.7296\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5562 - val_loss: 0.5353\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.4892\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.4649\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4467\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4212 - val_loss: 0.4324\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4283\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.4173\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.4094\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 0.4052\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3872 - val_loss: 0.3983\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.4161\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3801 - val_loss: 0.3946\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.3946\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3900\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3719 - val_loss: 0.3852\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3832\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3837\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 0.3794\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 0.3784\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3750\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3759\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3573 - val_loss: 0.3739\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 0.3688\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3538 - val_loss: 0.3708\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.3755\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3516 - val_loss: 0.3685\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.3638\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.3613\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3604\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3605\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3601\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3636\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3387 - val_loss: 0.3617\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3368 - val_loss: 0.3543\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.3548\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.3501\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.3519\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3322 - val_loss: 0.3530\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3468\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.3446\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3481\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3267 - val_loss: 0.3484\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3442\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.3439\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3241 - val_loss: 0.3476\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3434\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3205 - val_loss: 0.3377\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3187 - val_loss: 0.3451\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3188 - val_loss: 0.3404\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3169 - val_loss: 0.3432\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3163 - val_loss: 0.3396\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3143 - val_loss: 0.3344\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3138 - val_loss: 0.3378\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3130 - val_loss: 0.3362\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3106 - val_loss: 0.3333\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3105 - val_loss: 0.3407\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3103 - val_loss: 0.3334\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3077 - val_loss: 0.3294\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3100 - val_loss: 0.3305\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3079 - val_loss: 0.3262\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3065 - val_loss: 0.3306\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3108 - val_loss: 0.3256\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3039 - val_loss: 0.3275\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.302 - 1s 2ms/step - loss: 0.3024 - val_loss: 0.3300\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3030 - val_loss: 0.3283\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3301\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3029 - val_loss: 0.3226\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2987 - val_loss: 0.3259\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3027 - val_loss: 0.3220\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2995 - val_loss: 0.3224\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2972 - val_loss: 0.3436\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.3241\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.3199\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2957 - val_loss: 0.3224\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2948 - val_loss: 0.3209\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2952 - val_loss: 0.3235\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2934 - val_loss: 0.3193\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2921 - val_loss: 0.3189\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2928 - val_loss: 0.3207\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.3161\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2963 - val_loss: 0.3172\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2901 - val_loss: 0.3133\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2905 - val_loss: 0.3165\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2902 - val_loss: 0.3170\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2889 - val_loss: 0.3168\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2984 - val_loss: 0.3207\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2882 - val_loss: 0.3139\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2873 - val_loss: 0.3160\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2866 - val_loss: 0.3134\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2859 - val_loss: 0.3118\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2873 - val_loss: 0.3159\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2898 - val_loss: 0.3277\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2892 - val_loss: 0.3145\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2850 - val_loss: 0.3153\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2854 - val_loss: 0.3214\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 0.3181\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2859 - val_loss: 0.3128\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2840 - val_loss: 0.3109\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2776\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1555 - val_loss: 0.7996\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5714 - val_loss: 0.5854\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5130\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4488 - val_loss: 0.5025\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4232 - val_loss: 0.5146\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.5037\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.4925\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3866 - val_loss: 0.4702\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3802 - val_loss: 0.4503\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.4327\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.4153\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4009\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 0.3953\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3888\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3821\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.3841\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.3833\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3852\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.3917\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.3909\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3391 - val_loss: 0.3954\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3366 - val_loss: 0.3981\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.4059\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3326 - val_loss: 0.4228\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3323 - val_loss: 0.4327\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3985\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1707 - val_loss: 1.2796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9447 - val_loss: 1.8307\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7853 - val_loss: 0.6542\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 0.4697\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4327 - val_loss: 0.4460\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.4326\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.4200\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3889 - val_loss: 0.4136\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3796 - val_loss: 0.4049\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.4003\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3679 - val_loss: 0.3923\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3640 - val_loss: 0.3884\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.3861\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3564 - val_loss: 0.3829\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.3810\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3495 - val_loss: 0.3762\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3764\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.3681\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3432 - val_loss: 0.3724\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3649\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3387 - val_loss: 0.3655\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3369 - val_loss: 0.3623\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.3610\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3323 - val_loss: 0.3582\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3566\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3293 - val_loss: 0.3567\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3267 - val_loss: 0.3591\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3271 - val_loss: 0.3548\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3247 - val_loss: 0.3525\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3218 - val_loss: 0.3496\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3203 - val_loss: 0.3465\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3480\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3188 - val_loss: 0.3501\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3483\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.3419\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3135 - val_loss: 0.3468\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3142 - val_loss: 0.3439\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3114 - val_loss: 0.3456\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3101 - val_loss: 0.3405\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3089 - val_loss: 0.3421\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3071 - val_loss: 0.3435\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3090 - val_loss: 0.3348\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3045 - val_loss: 0.3379\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3358\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3025 - val_loss: 0.3339\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3021 - val_loss: 0.3353\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3006 - val_loss: 0.3332\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3023 - val_loss: 0.3311\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.3327\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.3329\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2964 - val_loss: 0.3303\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2957 - val_loss: 0.3278\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2945 - val_loss: 0.3316\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2941 - val_loss: 0.3311\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2929 - val_loss: 0.3250\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2964 - val_loss: 0.3271\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2940 - val_loss: 0.3236\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2904 - val_loss: 0.3195\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2903 - val_loss: 0.3191\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2885 - val_loss: 0.3323\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2905 - val_loss: 0.3239\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2878 - val_loss: 0.3206\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2887 - val_loss: 0.3184\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2856 - val_loss: 0.3198\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2847 - val_loss: 0.3222\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2850 - val_loss: 0.3163\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2836 - val_loss: 0.3294\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2835 - val_loss: 0.3161\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2824 - val_loss: 0.3147\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2816 - val_loss: 0.3213\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2801 - val_loss: 0.3170\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2800 - val_loss: 0.3274\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2783 - val_loss: 0.3116\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2773 - val_loss: 0.3114\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2764 - val_loss: 0.3135\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2765 - val_loss: 0.3101\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2748 - val_loss: 0.3133\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2749 - val_loss: 0.3112\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2774 - val_loss: 0.3114\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2742 - val_loss: 0.3072\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2749 - val_loss: 0.3103\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2761 - val_loss: 0.3082\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2728 - val_loss: 0.3120\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2718 - val_loss: 0.3080\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2722 - val_loss: 0.3051\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2715 - val_loss: 0.3059\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2705 - val_loss: 0.3115\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2706 - val_loss: 0.3055\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2698 - val_loss: 0.3012\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2697 - val_loss: 0.3020\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2703 - val_loss: 0.3352\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2719 - val_loss: 0.3046\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2666 - val_loss: 0.3056\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2669 - val_loss: 0.3161\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2671 - val_loss: 0.3005\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2657 - val_loss: 0.3039\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2666 - val_loss: 0.3163\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2653 - val_loss: 0.3078\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2658 - val_loss: 0.3022\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2646 - val_loss: 0.3042\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3075\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1226 - val_loss: 1.4958\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4204 - val_loss: 14.8888\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 15.7981 - val_loss: 214.0121\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 355.1969 - val_loss: 3621.9031\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5527.5723 - val_loss: 61632.3008\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 29716.4688 - val_loss: 1064446.7500\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 169044.2188 - val_loss: 18234088.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 8765162.0000 - val_loss: 305668288.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 105040792.0000 - val_loss: 5219588096.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3080220928.0000 - val_loss: 87483179008.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 12186662912.0000 - val_loss: 1499307442176.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9877683200.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2363 - val_loss: 0.6679\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5608 - val_loss: 0.7440\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 1.0576\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 1.3901\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 1.5639\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 1.7281\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4935 - val_loss: 1.7237\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 1.9276\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 1.9948\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4999 - val_loss: 1.8913\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 2.0569\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6589\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1823 - val_loss: 48.6562\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6.6857 - val_loss: 1031.3464\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1449.1794 - val_loss: 28568.1152\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 36058.1172 - val_loss: 792240.6875\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 339628.1875 - val_loss: 22178128.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3284611.7500 - val_loss: 624675968.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 830957120.0000 - val_loss: 17288781824.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6715129856.0000 - val_loss: 478254137344.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 166022955008.0000 - val_loss: 13123479142400.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 14604487884800.0000 - val_loss: 360694708961280.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 141855220039680.0000 - val_loss: 10153798756466688.0000\n",
      "121/121 [==============================] - 0s 923us/step - loss: 215668360216576.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7249 - val_loss: 0.8482\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7302 - val_loss: 0.7532\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.6103\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 0.5715\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5264 - val_loss: 0.5399\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4979 - val_loss: 0.5145\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.4899\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4538 - val_loss: 0.4722\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4379 - val_loss: 0.4574\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4459\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4174 - val_loss: 0.4338\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4077 - val_loss: 0.4244\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4016 - val_loss: 0.4207\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.4150\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 0.4090\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.4032\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.4003\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.3945\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.3924\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3883\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3854\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3829\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.3803\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.3797\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.3807\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3584 - val_loss: 0.3765\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3556 - val_loss: 0.3726\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.3737\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.3675\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.3782\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.3656\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3663\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3464 - val_loss: 0.3615\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3677\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.3594\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3411 - val_loss: 0.3663\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3574\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 0.3615\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3380 - val_loss: 0.3601\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3376 - val_loss: 0.3592\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 0.3538\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.3701\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3355 - val_loss: 0.3543\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.3621\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3313 - val_loss: 0.3536\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3593\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.3505\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3272 - val_loss: 0.3512\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3264 - val_loss: 0.3465\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3249 - val_loss: 0.3579\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3469\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3230 - val_loss: 0.3521\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3226 - val_loss: 0.3414\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3210 - val_loss: 0.3496\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3213 - val_loss: 0.3414\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3202 - val_loss: 0.3446\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3188 - val_loss: 0.3403\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3174 - val_loss: 0.3480\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3397\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.3461\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3159 - val_loss: 0.3389\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3137 - val_loss: 0.3441\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3125 - val_loss: 0.3375\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.3457\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3127 - val_loss: 0.3397\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3135 - val_loss: 0.3638\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3325\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3114 - val_loss: 0.3425\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3106 - val_loss: 0.3314\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3075 - val_loss: 0.3387\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3293\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3055 - val_loss: 0.3335\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3048 - val_loss: 0.3306\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3414\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3035 - val_loss: 0.3315\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3026 - val_loss: 0.3282\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3021 - val_loss: 0.3278\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3013 - val_loss: 0.3293\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.3348\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3018 - val_loss: 0.3216\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3306\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2981 - val_loss: 0.3299\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2980 - val_loss: 0.3242\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2960 - val_loss: 0.3272\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2963 - val_loss: 0.3244\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2961 - val_loss: 0.3236\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2947 - val_loss: 0.3254\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2943 - val_loss: 0.3248\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2942 - val_loss: 0.3188\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2936 - val_loss: 0.3264\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2926 - val_loss: 0.3202\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2915 - val_loss: 0.3243\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2909 - val_loss: 0.3264\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2906 - val_loss: 0.3240\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2914 - val_loss: 0.3207\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2903 - val_loss: 0.3291\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2900 - val_loss: 0.3166\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2898 - val_loss: 0.3243\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2880 - val_loss: 0.3165\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2887 - val_loss: 0.3313\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2885\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2549 - val_loss: 1.9672\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6373 - val_loss: 1.3537\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5656 - val_loss: 0.9720\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5178 - val_loss: 0.7584\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.6062\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4582 - val_loss: 0.5299\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4386 - val_loss: 0.4877\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 0.4575\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 0.4421\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.4309\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.4218\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4173\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.4107\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.4031\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.4004\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3644 - val_loss: 0.3925\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.3942\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3855\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.3839\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.3809\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3821\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3461 - val_loss: 0.3783\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3796\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.3786\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.3802\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3356 - val_loss: 0.3751\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3775\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3727\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3291 - val_loss: 0.3749\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3763\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3254 - val_loss: 0.3740\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3237 - val_loss: 0.3749\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3224 - val_loss: 0.3772\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3202 - val_loss: 0.3832\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3188 - val_loss: 0.3822\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3171 - val_loss: 0.3840\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3164 - val_loss: 0.3826\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3146 - val_loss: 0.3911\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3722\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2326 - val_loss: 0.8008\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6898 - val_loss: 0.6610\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5810 - val_loss: 0.5954\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5347 - val_loss: 0.5521\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4980 - val_loss: 0.5161\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4700 - val_loss: 0.4901\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4472 - val_loss: 0.4693\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.4512\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.4380\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.4268\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.4177\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3866 - val_loss: 0.4104\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.4028\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 0.3985\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.3953\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.3899\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.3890\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3567 - val_loss: 0.3813\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.3840\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3500 - val_loss: 0.3776\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3468 - val_loss: 0.3754\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.3726\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.3664\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3389 - val_loss: 0.3686\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3637\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.3629\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3328 - val_loss: 0.3601\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3304 - val_loss: 0.3621\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.3571\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3273 - val_loss: 0.3586\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3565\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3244 - val_loss: 0.3518\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3494\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3200 - val_loss: 0.3550\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3190 - val_loss: 0.3469\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3177 - val_loss: 0.3500\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3162 - val_loss: 0.3504\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.3465\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3135 - val_loss: 0.3451\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3122 - val_loss: 0.3490\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 0.3441\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3099 - val_loss: 0.3406\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3087 - val_loss: 0.3430\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3079 - val_loss: 0.3409\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3060 - val_loss: 0.3420\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3050 - val_loss: 0.3448\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3044 - val_loss: 0.3437\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3039 - val_loss: 0.3345\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3546\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3025 - val_loss: 0.3327\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 0.3360\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2995 - val_loss: 0.3355\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 0.3304\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2977 - val_loss: 0.3326\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2964 - val_loss: 0.3310\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2966 - val_loss: 0.3294\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2953 - val_loss: 0.3316\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2939 - val_loss: 0.3309\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2940 - val_loss: 0.3310\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2924 - val_loss: 0.3249\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2914 - val_loss: 0.3278\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2907 - val_loss: 0.3238\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2901 - val_loss: 0.3302\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2896 - val_loss: 0.3235\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2890 - val_loss: 0.3229\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2873 - val_loss: 0.3254\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2874 - val_loss: 0.3227\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2872 - val_loss: 0.3345\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2857 - val_loss: 0.3233\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2884 - val_loss: 0.3231\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2855 - val_loss: 0.3243\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2839 - val_loss: 0.3200\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2830 - val_loss: 0.3231\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2824 - val_loss: 0.3236\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2819 - val_loss: 0.3205\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2811 - val_loss: 0.3186\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2802 - val_loss: 0.3176\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2798 - val_loss: 0.3174\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2792 - val_loss: 0.3219\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2793 - val_loss: 0.3241\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2784 - val_loss: 0.3176\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2773 - val_loss: 0.3169\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2774 - val_loss: 0.3160\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2769 - val_loss: 0.3157\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2763 - val_loss: 0.3110\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2759 - val_loss: 0.3150\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2758 - val_loss: 0.3120\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2746 - val_loss: 0.3166\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2755 - val_loss: 0.3116\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2732 - val_loss: 0.3249\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2732 - val_loss: 0.3132\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2723 - val_loss: 0.3134\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2722 - val_loss: 0.3109\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2713 - val_loss: 0.3140\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2705 - val_loss: 0.3113\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2699 - val_loss: 0.3168\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2704 - val_loss: 0.3108\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2697 - val_loss: 0.3122\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2692 - val_loss: 0.3087\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2686 - val_loss: 0.3149\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3145\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3297 - val_loss: 0.9575\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8490 - val_loss: 0.8268\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7644 - val_loss: 0.7713\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7262 - val_loss: 0.7435\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6877 - val_loss: 0.6996\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6561 - val_loss: 0.6678\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.6414\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6214\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5807 - val_loss: 0.5947\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 0.5836\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 0.5607\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.5436\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5110 - val_loss: 0.5335\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.5149\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.5073\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.4907\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.4922\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.4736\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.4868\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.4613\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.4644\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4522\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.4678\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.4591\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.5084\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4683\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4909\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4574\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 0.4523\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.4239\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4051 - val_loss: 0.4253\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.4121\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.4152\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.4057\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.4066\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4019\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.4023\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3981\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3977\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.3937\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3954\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.3915\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.3956\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.3883\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3930\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3884\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3920\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3856\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3839\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.3830\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.3823\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.3807\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3644 - val_loss: 0.3833\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3787\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.3795\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.3761\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.3757\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3594 - val_loss: 0.3761\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.3736\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3782\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3573 - val_loss: 0.3733\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3563 - val_loss: 0.3756\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.3712\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.3767\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3548 - val_loss: 0.3713\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.3722\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.3673\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3519 - val_loss: 0.3712\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3511 - val_loss: 0.3675\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.3693\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.3682\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.3664\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3483 - val_loss: 0.3665\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 0.3645\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3468 - val_loss: 0.3658\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.3647\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.3626\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.3638\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.3633\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.3623\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.3645\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3430 - val_loss: 0.3619\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3423 - val_loss: 0.3601\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.3604\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3597\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3407 - val_loss: 0.3595\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3600\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.3596\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3579\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.3601\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.3585\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3582\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.3569\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3370 - val_loss: 0.3583\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.3541\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3362 - val_loss: 0.3594\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3361 - val_loss: 0.3560\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.3564\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 0.3542\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.3533\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3156\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9192 - val_loss: 1.7764\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7532 - val_loss: 1.4259\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6738 - val_loss: 1.2134\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 1.0369\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 0.9115\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5627 - val_loss: 0.8121\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5364 - val_loss: 0.7220\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5139 - val_loss: 0.6501\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4779 - val_loss: 0.5551\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.5226\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.4941\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4424 - val_loss: 0.4773\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4335 - val_loss: 0.4656\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.4575\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.4523\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.4488\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.4489\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 0.4478\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4462\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.4460\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4473\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4469\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3870 - val_loss: 0.4500\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.4473\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.4461\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3798 - val_loss: 0.4438\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.4425\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4412\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.4399\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.4391\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3704 - val_loss: 0.4350\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3686 - val_loss: 0.4316\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.4307\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3657 - val_loss: 0.4277\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3645 - val_loss: 0.4246\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3629 - val_loss: 0.4239\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.4188\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.4150\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.4137\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3578 - val_loss: 0.4092\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3566 - val_loss: 0.4073\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3556 - val_loss: 0.4039\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4010\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.3988\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3962\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 0.3939\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3909\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3890\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.3885\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.3866\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.3832\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3459 - val_loss: 0.3835\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3805\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.3790\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3430 - val_loss: 0.3775\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 0.3768\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3419 - val_loss: 0.3748\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3408 - val_loss: 0.3755\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3403 - val_loss: 0.3738\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.3718\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3384 - val_loss: 0.3726\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.3701\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3367 - val_loss: 0.3712\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3365 - val_loss: 0.3701\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3698\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 0.3681\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.3737\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3335 - val_loss: 0.3698\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3332 - val_loss: 0.3690\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3324 - val_loss: 0.3670\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3664\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.3685\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3306 - val_loss: 0.3688\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3674\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3295 - val_loss: 0.3656\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3291 - val_loss: 0.3691\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.3683\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3276 - val_loss: 0.3673\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3674\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3265 - val_loss: 0.3689\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3262 - val_loss: 0.3692\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3689\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3251 - val_loss: 0.3715\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.3693\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3241 - val_loss: 0.3700\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3666\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2429 - val_loss: 1.0785\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8363 - val_loss: 0.7802\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6952 - val_loss: 0.6981\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6393 - val_loss: 0.6572\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6005 - val_loss: 0.6221\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5702 - val_loss: 0.5918\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 0.5730\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.5511\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 0.5351\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5266\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.5103\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.4990\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.4893\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.4824\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.4735\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4394 - val_loss: 0.4706\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4338 - val_loss: 0.4627\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.4555\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.4518\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4443\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 0.4402\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.4369\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.4336\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.4298\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.4272\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4229\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.4212\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.4162\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.4154\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4130\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.4099\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4084\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4081\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4042\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4026\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3995\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3982\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.3975\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3951\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.3950\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3634 - val_loss: 0.3937\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3619 - val_loss: 0.3912\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.3924\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.3880\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3581 - val_loss: 0.3883\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 0.3869\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 0.3871\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.3842\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.3857\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3523 - val_loss: 0.3832\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3514 - val_loss: 0.3850\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3504 - val_loss: 0.3803\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.3823\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3484 - val_loss: 0.3803\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 0.3783\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.3785\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.3773\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 0.3764\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3769\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.3759\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3756\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.3742\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3723\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.3750\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.3724\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3734\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.3714\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.3704\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3696\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3365 - val_loss: 0.3701\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3362 - val_loss: 0.3724\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.3692\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.3698\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.3677\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3335 - val_loss: 0.3666\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.3681\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3324 - val_loss: 0.3662\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.3671\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.3631\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3308 - val_loss: 0.3631\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.3666\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3631\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3291 - val_loss: 0.3644\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3283 - val_loss: 0.3627\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.3640\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3275 - val_loss: 0.3617\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3269 - val_loss: 0.3612\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3268 - val_loss: 0.3617\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3258 - val_loss: 0.3609\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3254 - val_loss: 0.3611\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3250 - val_loss: 0.3609\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3243 - val_loss: 0.3628\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3243 - val_loss: 0.3579\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3607\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3236 - val_loss: 0.3582\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3230 - val_loss: 0.3587\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3223 - val_loss: 0.3560\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3226 - val_loss: 0.3581\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3217 - val_loss: 0.3561\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3212 - val_loss: 0.3562\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9709 - val_loss: 0.7185\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6731 - val_loss: 1.8201\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8252 - val_loss: 1.0176\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6521 - val_loss: 0.5313\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4671 - val_loss: 0.4693\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4387 - val_loss: 0.4508\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4265 - val_loss: 0.4467\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4174 - val_loss: 0.4345\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4118 - val_loss: 0.4285\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4067 - val_loss: 0.4212\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4027 - val_loss: 0.4203\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4188\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3959 - val_loss: 0.4149\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3946 - val_loss: 0.4095\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3918 - val_loss: 0.4096\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3898 - val_loss: 0.4072\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.4081\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4030\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4071\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.4017\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3997\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.3979\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.3951\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3967\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.3955\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3972\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3946\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.3937\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3965\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3892\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3869\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3879\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3960\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3859\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3849\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3652 - val_loss: 0.3848\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.3851\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3643 - val_loss: 0.3819\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3635 - val_loss: 0.3812\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3819\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.3844\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 0.3804\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.3797\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.3848\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3585 - val_loss: 0.3812\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3594 - val_loss: 0.3806\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3575 - val_loss: 0.3770\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3757\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 0.3767\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3549 - val_loss: 0.3788\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 0.3785\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3535 - val_loss: 0.3791\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 0.3734\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.3724\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3535 - val_loss: 0.3723\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3535 - val_loss: 0.3809\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3542 - val_loss: 0.3766\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3505 - val_loss: 0.3713\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3693\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 0.3804\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.3664\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.3709\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.3691\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3678\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.3680\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.3675\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.3685\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.3642\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3423 - val_loss: 0.3634\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.3790\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3431 - val_loss: 0.3681\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3433 - val_loss: 0.3610\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.3639\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3397 - val_loss: 0.3676\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3623\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.3624\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.3813\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.3643\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3598\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3384 - val_loss: 0.3594\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3604\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.3584\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3355 - val_loss: 0.3635\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.3628\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 0.3587\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3337 - val_loss: 0.3596\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3400 - val_loss: 0.3560\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.3627\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3323 - val_loss: 0.3553\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.3544\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.3575\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3321 - val_loss: 0.3547\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3545\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3552\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3294 - val_loss: 0.3557\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3312 - val_loss: 0.3539\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3515\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.3511\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3268 - val_loss: 0.3483\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.3539\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3139\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9901 - val_loss: 0.6927\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5737 - val_loss: 0.6223\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 0.6446\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 0.6793\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4483 - val_loss: 0.7236\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.7152\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.6975\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.6691\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.6386\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.5774\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.5463\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.5105\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.4801\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.4557\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.4351\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.4202\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.4086\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3998\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.3965\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3942\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.3936\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.3957\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3567 - val_loss: 0.3997\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.4038\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.4128\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 0.4185\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.4214\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.4258\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.4374\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.4513\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.4507\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4162\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9972 - val_loss: 1.0218\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 0.6984\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7543 - val_loss: 4.3314\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2946 - val_loss: 6.5216\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6076 - val_loss: 2.4194\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9943 - val_loss: 0.5103\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.4385\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.4246\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.4199\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 0.4235\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.4008\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3978\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3935\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.3935\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3979\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.3920\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3583 - val_loss: 0.3888\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.3869\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3563 - val_loss: 0.4390\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.3874\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.3791\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3491 - val_loss: 0.3774\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3474 - val_loss: 0.3781\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 0.3756\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3440 - val_loss: 0.3740\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.3765\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3450 - val_loss: 0.3792\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.3773\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3382 - val_loss: 0.3733\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3741\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3365 - val_loss: 0.3694\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.3728\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3753\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.3703\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3328 - val_loss: 0.3685\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.3676\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.3659\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3645\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3310 - val_loss: 0.3675\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3287 - val_loss: 0.3659\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3683\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3266 - val_loss: 0.3683\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3264 - val_loss: 0.3658\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3250 - val_loss: 0.3698\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3248 - val_loss: 0.3621\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.3646\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3598\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3594\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 0.3601\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3205 - val_loss: 0.3598\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3218 - val_loss: 0.3642\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3195 - val_loss: 0.3589\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3585\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.3574\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3163 - val_loss: 0.3611\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3257 - val_loss: 0.3622\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3172 - val_loss: 0.3599\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3187 - val_loss: 0.3552\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3155 - val_loss: 0.3534\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3174 - val_loss: 0.3566\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.3539\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3152 - val_loss: 0.3532\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3135 - val_loss: 0.3526\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.3516\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3122 - val_loss: 0.3545\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 0.3520\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3111 - val_loss: 0.3507\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3110 - val_loss: 0.3505\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3096 - val_loss: 0.3521\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3110 - val_loss: 0.3526\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3082 - val_loss: 0.3549\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 0.3511\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 0.3700\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3103 - val_loss: 0.3490\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3076 - val_loss: 0.3566\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3070 - val_loss: 0.3481\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3067 - val_loss: 0.3462\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3070 - val_loss: 0.3528\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.3551\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3052 - val_loss: 0.3495\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.3458\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3044 - val_loss: 0.3522\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3052 - val_loss: 0.3449\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3473\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3023 - val_loss: 0.3481\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3031 - val_loss: 0.3445\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3020 - val_loss: 0.3422\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.3456\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3018 - val_loss: 0.3432\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3042 - val_loss: 0.3450\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 0.3455\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3468\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3400\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2994 - val_loss: 0.3489\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3024 - val_loss: 0.3451\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3025 - val_loss: 0.3437\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2988 - val_loss: 0.3413\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2992 - val_loss: 0.3458\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2963 - val_loss: 0.3456\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3050 - val_loss: 0.3443\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3274\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 3.8102 - val_loss: 2.6128\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0380 - val_loss: 1.7169\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5369 - val_loss: 1.4615\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3949 - val_loss: 1.3861\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3542 - val_loss: 1.3636\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3426 - val_loss: 1.3568\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3393 - val_loss: 1.3544\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3383 - val_loss: 1.3536\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3379 - val_loss: 1.3532\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3378 - val_loss: 1.3531\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3378 - val_loss: 1.3530\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3378 - val_loss: 1.3529\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3378 - val_loss: 1.3529\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3378 - val_loss: 1.3529\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3378 - val_loss: 1.3528\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3378 - val_loss: 1.3528\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3528\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3528\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3528\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3527\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3527\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3527\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3527\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3527\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3527\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3527\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3376 - val_loss: 1.3526\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3525\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3376 - val_loss: 1.3526\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3376 - val_loss: 1.3526\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3376 - val_loss: 1.3526\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3376 - val_loss: 1.3526\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3526\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3307\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.8320 - val_loss: 2.5718\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9636 - val_loss: 1.6509\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.3664\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2617 - val_loss: 1.2634\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1745 - val_loss: 1.2069\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0883 - val_loss: 1.1682\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 1.1708\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8697 - val_loss: 1.2333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7887 - val_loss: 1.3041\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7425 - val_loss: 1.3225\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7168 - val_loss: 1.3018\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6996 - val_loss: 1.2494\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6861 - val_loss: 1.2024\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6746 - val_loss: 1.1499\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6641 - val_loss: 1.1063\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 1.0405\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6457 - val_loss: 0.9702\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.9052\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8568\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6213 - val_loss: 0.8063\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.7705\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.7313\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6992\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5929 - val_loss: 0.6710\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5863 - val_loss: 0.6442\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5796 - val_loss: 0.6242\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 0.6107\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - val_loss: 0.6030\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5592 - val_loss: 0.5968\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5530 - val_loss: 0.5894\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 0.5831\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 0.5770\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 0.5713\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 0.5641\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5578\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5184 - val_loss: 0.5518\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5129 - val_loss: 0.5456\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5401\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5025 - val_loss: 0.5344\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4976 - val_loss: 0.5288\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4928 - val_loss: 0.5237\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4883 - val_loss: 0.5182\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.5134\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.5084\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5051\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.4998\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.4957\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.4918\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.4889\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.4846\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.4809\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.4773\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4457 - val_loss: 0.4740\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4424 - val_loss: 0.4712\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4681\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4648\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.4622\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 0.4590\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 0.4575\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.4551\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.4521\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4223 - val_loss: 0.4499\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4202 - val_loss: 0.4482\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.4471\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.4448\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.4434\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.4416\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.4404\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.4388\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.4384\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4089 - val_loss: 0.4365\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.4355\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.4338\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4340\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4333\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4034 - val_loss: 0.4326\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.4304\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.4295\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 0.4294\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.4281\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3986 - val_loss: 0.4271\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3981 - val_loss: 0.4262\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4257\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3966 - val_loss: 0.4249\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.4249\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4240\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4230\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4222\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4224\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.4228\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.4210\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.4225\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 0.4198\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 0.4193\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.4194\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.4189\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.4188\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 0.4188\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.4189\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.4184\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4206\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.5607 - val_loss: 2.1037\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6387 - val_loss: 1.4188\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3405 - val_loss: 1.2837\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2335 - val_loss: 1.1819\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1411 - val_loss: 1.0876\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0491 - val_loss: 0.9989\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9552 - val_loss: 0.9138\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8715 - val_loss: 0.8478\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8117 - val_loss: 0.7999\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7677 - val_loss: 0.7630\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7306 - val_loss: 0.7300\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6967 - val_loss: 0.6994\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6636 - val_loss: 0.6690\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6330 - val_loss: 0.6420\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6179\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5820 - val_loss: 0.5954\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5607 - val_loss: 0.5735\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5415 - val_loss: 0.5552\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 0.5379\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5110 - val_loss: 0.5239\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4997 - val_loss: 0.5128\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5027\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.4947\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4743 - val_loss: 0.4869\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.4806\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.4753\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.4703\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.4647\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.4606\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.4575\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4545\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4506\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.4485\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4320 - val_loss: 0.4463\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 0.4431\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4277 - val_loss: 0.4409\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4254 - val_loss: 0.4389\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4235 - val_loss: 0.4362\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.4350\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4198 - val_loss: 0.4327\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4182 - val_loss: 0.4323\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.4304\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4286\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.4280\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.4298\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.4260\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 0.4274\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.4255\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.4230\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.4227\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.4212\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.4215\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.4219\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4051 - val_loss: 0.4198\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4040 - val_loss: 0.4185\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4036 - val_loss: 0.4169\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.4177\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 0.4172\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4020 - val_loss: 0.4167\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4014 - val_loss: 0.4161\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.4163\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 0.4179\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 0.4142\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.4144\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3994 - val_loss: 0.4146\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.4132\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 0.4141\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.4140\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.4122\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4120\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4127\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4114\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3968 - val_loss: 0.4110\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4116\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3965 - val_loss: 0.4108\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4105\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3960 - val_loss: 0.4111\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.4117\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4091\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3952 - val_loss: 0.4099\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3952 - val_loss: 0.4091\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4105\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 0.4092\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 0.4091\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4081\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4088\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.4080\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3941 - val_loss: 0.4079\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.4095\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4080\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4075\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4072\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.4064\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.4076\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4061\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.4080\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.4082\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.4053\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.4083\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.4055\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3985\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4109 - val_loss: 8.4941\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.6790 - val_loss: 86.3445\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 18.4094 - val_loss: 770.7706\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 159.9398 - val_loss: 7373.7012\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1465.5465 - val_loss: 68836.1328\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 12720.8711 - val_loss: 644848.0625\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 127556.5469 - val_loss: 6057248.5000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3871696.2500 - val_loss: 56946808.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 30121006.0000 - val_loss: 535134624.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 120965304.0000 - val_loss: 5059801088.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3632524288.0000 - val_loss: 47378010112.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 300335040.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2057 - val_loss: 0.7893\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 0.5617\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 0.5914\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5031 - val_loss: 0.7219\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4986 - val_loss: 0.9141\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 1.0881\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 1.2360\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 1.3838\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 1.5341\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 1.6192\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 1.7195\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 1.8134\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4892\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5060 - val_loss: 3.2775\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8092 - val_loss: 41.5024\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 23.5024 - val_loss: 487.6916\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 333.7767 - val_loss: 5963.2490\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3850.1985 - val_loss: 72932.5938\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 25695.3867 - val_loss: 890873.6875\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 546810.9375 - val_loss: 10908845.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2776288.0000 - val_loss: 135091536.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 69533808.0000 - val_loss: 1640974464.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 523318432.0000 - val_loss: 20087873536.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9812766720.0000 - val_loss: 245239676928.0000\n",
      "121/121 [==============================] - 0s 997us/step - loss: 5274610688.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8623 - val_loss: 5.5691\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9091 - val_loss: 38.6669\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 8.4367 - val_loss: 198.7332\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 96.8980 - val_loss: 1147.1865\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 262.9049 - val_loss: 6458.9277\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2626.1338 - val_loss: 36844.4609\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 18838.0469 - val_loss: 208756.3594\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 42092.2891 - val_loss: 1190117.2500\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 246362.3281 - val_loss: 6741221.5000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1695688.7500 - val_loss: 38138432.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 19773110.0000 - val_loss: 217215536.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1354007.1250\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4294 - val_loss: 0.9396\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5200 - val_loss: 1.0670\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 1.2199\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 1.3546\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 1.4600\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 1.5828\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 1.6847\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 1.7733\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 1.8163\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 1.8685\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 1.9260\n",
      "121/121 [==============================] - 0s 972us/step - loss: 1.5626\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2292 - val_loss: 8.9488\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.3092 - val_loss: 59.6934\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 24.1550 - val_loss: 389.1627\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 98.4041 - val_loss: 2778.7542\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1074.3158 - val_loss: 18849.2988\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4547.5815 - val_loss: 131901.7656\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 32611.9355 - val_loss: 912607.4375\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 365430.6875 - val_loss: 6259685.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1806845.0000 - val_loss: 43151032.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 20786428.0000 - val_loss: 298845248.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 146217456.0000 - val_loss: 2062037120.0000\n",
      "121/121 [==============================] - 0s 948us/step - loss: 43849908.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4499 - val_loss: 0.6928\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5982\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 0.5098\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.4800\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.4550\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4330 - val_loss: 0.4401\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4199 - val_loss: 0.4328\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.4199\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.4166\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.4082\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4052\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3995\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3956\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3787 - val_loss: 0.3935\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3871\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3866\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3816\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3841\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.3813\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3630 - val_loss: 0.3788\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.3764\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3585 - val_loss: 0.3739\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.3704\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.3705\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3686\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.3674\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 0.3648\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.3653\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3477 - val_loss: 0.3654\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.3706\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3459 - val_loss: 0.3647\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.3629\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3629\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.3573\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.3594\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3387 - val_loss: 0.3578\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3379 - val_loss: 0.3589\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.3540\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3360 - val_loss: 0.3524\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3348 - val_loss: 0.3539\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3335 - val_loss: 0.3531\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3517\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3489\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3313 - val_loss: 0.3472\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3511\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.3489\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.3511\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.3509\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3266 - val_loss: 0.3444\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3250 - val_loss: 0.3446\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.3446\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3240 - val_loss: 0.3436\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3231 - val_loss: 0.3455\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.3431\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3221 - val_loss: 0.3461\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 0.3460\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3198 - val_loss: 0.3412\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3190 - val_loss: 0.3443\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.3392\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3176 - val_loss: 0.3372\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3170 - val_loss: 0.3429\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.3403\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3159 - val_loss: 0.3415\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3152 - val_loss: 0.3373\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.3427\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.3351\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3118 - val_loss: 0.3424\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3122 - val_loss: 0.3320\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3114 - val_loss: 0.3385\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3109 - val_loss: 0.3335\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.3344\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3091 - val_loss: 0.3365\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3085 - val_loss: 0.3356\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.3316\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3074 - val_loss: 0.3328\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3287\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.3390\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3066 - val_loss: 0.3277\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3047 - val_loss: 0.3483\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3061 - val_loss: 0.3331\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3048 - val_loss: 0.3517\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3071 - val_loss: 0.3365\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3569\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3096 - val_loss: 0.3321\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3067 - val_loss: 0.3524\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3062 - val_loss: 0.3258\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3027 - val_loss: 0.3409\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3005 - val_loss: 0.3245\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2992 - val_loss: 0.3317\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2988 - val_loss: 0.3214\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2968 - val_loss: 0.3382\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2982 - val_loss: 0.3217\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2962 - val_loss: 0.3282\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2967 - val_loss: 0.3269\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2952 - val_loss: 0.3332\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2953 - val_loss: 0.3241\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2948 - val_loss: 0.3259\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2938 - val_loss: 0.3233\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2940 - val_loss: 0.3204\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2929 - val_loss: 0.3276\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.2905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3812 - val_loss: 0.8020\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5924 - val_loss: 0.6080\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5246 - val_loss: 0.5467\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4831 - val_loss: 0.5274\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4557 - val_loss: 0.5113\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4351 - val_loss: 0.4914\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4754\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.4643\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4401\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.4303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3839 - val_loss: 0.4197\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3777 - val_loss: 0.4110\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.4070\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.4010\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3649 - val_loss: 0.3987\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3969\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3954\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 0.3987\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3519 - val_loss: 0.4011\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3495 - val_loss: 0.4065\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.4012\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3443 - val_loss: 0.4059\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3419 - val_loss: 0.4073\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3393 - val_loss: 0.4034\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3385 - val_loss: 0.4044\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3356 - val_loss: 0.4045\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.4110\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4099 - val_loss: 1.1013\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7364 - val_loss: 0.6302\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5656 - val_loss: 0.5767\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5089 - val_loss: 0.5201\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.4850\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4578\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.4375\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4285\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3886 - val_loss: 0.4193\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3804 - val_loss: 0.4106\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.4019\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.4003\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3612 - val_loss: 0.3926\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3569 - val_loss: 0.4008\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.3848\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.3901\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3477 - val_loss: 0.3836\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3792\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3746\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3391 - val_loss: 0.3758\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3383 - val_loss: 0.3699\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3692\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3343 - val_loss: 0.3663\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.3653\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3296 - val_loss: 0.3672\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.3663\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3273 - val_loss: 0.3602\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3257 - val_loss: 0.3566\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3242 - val_loss: 0.3583\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3223 - val_loss: 0.3541\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3210 - val_loss: 0.3521\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3193 - val_loss: 0.3504\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3184 - val_loss: 0.3517\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3172 - val_loss: 0.3490\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.3515\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3142 - val_loss: 0.3482\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.3465\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3118 - val_loss: 0.3439\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3103 - val_loss: 0.3542\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3479\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3546\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.3453\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3073 - val_loss: 0.3434\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3068 - val_loss: 0.3400\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3054 - val_loss: 0.3385\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.3395\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3033 - val_loss: 0.3388\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.3386\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3407\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.3387\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2999 - val_loss: 0.3347\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2973 - val_loss: 0.3363\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2972 - val_loss: 0.3460\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2972 - val_loss: 0.3373\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2964 - val_loss: 0.3381\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2960 - val_loss: 0.3319\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2958 - val_loss: 0.3381\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2947 - val_loss: 0.3294\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2937 - val_loss: 0.3385\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2930 - val_loss: 0.3275\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2909 - val_loss: 0.3351\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2911 - val_loss: 0.3271\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2912 - val_loss: 0.3333\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2892 - val_loss: 0.3303\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2888 - val_loss: 0.3292\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2889 - val_loss: 0.3232\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.3228\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.3277\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2872 - val_loss: 0.3211\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2857 - val_loss: 0.3285\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2857 - val_loss: 0.3189\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2850 - val_loss: 0.3271\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2850 - val_loss: 0.3193\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2839 - val_loss: 0.3286\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2834 - val_loss: 0.3232\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2821 - val_loss: 0.3264\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2825 - val_loss: 0.3191\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2814 - val_loss: 0.3316\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2812 - val_loss: 0.3201\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2811 - val_loss: 0.3299\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2804 - val_loss: 0.3159\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.3273\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2799 - val_loss: 0.3162\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2795 - val_loss: 0.3255\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2781 - val_loss: 0.3214\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2789 - val_loss: 0.3275\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2771 - val_loss: 0.3160\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2766 - val_loss: 0.3332\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2772 - val_loss: 0.3265\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2778 - val_loss: 0.3397\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2781 - val_loss: 0.3165\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3290\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 5.9025 - val_loss: 5.1970\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.3095 - val_loss: 3.8286\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.2162 - val_loss: 2.8854\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4567 - val_loss: 2.2288\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9236 - val_loss: 1.7668\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5463 - val_loss: 1.4398\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2775 - val_loss: 1.2062\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0849 - val_loss: 1.0392\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9187\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8460 - val_loss: 0.8317\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7733 - val_loss: 0.7686\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7204 - val_loss: 0.7223\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6817 - val_loss: 0.6885\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6533 - val_loss: 0.6636\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6324 - val_loss: 0.6452\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.6316\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6213\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5965 - val_loss: 0.6134\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5899 - val_loss: 0.6075\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5848 - val_loss: 0.6029\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5809 - val_loss: 0.5993\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5777 - val_loss: 0.5964\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5751 - val_loss: 0.5940\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5731 - val_loss: 0.5920\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - val_loss: 0.5903\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5697 - val_loss: 0.5887\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5684 - val_loss: 0.5873\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5671 - val_loss: 0.5862\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5661 - val_loss: 0.5851\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5651 - val_loss: 0.5841\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5641 - val_loss: 0.5831\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5632 - val_loss: 0.5821\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5624 - val_loss: 0.5812\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5615 - val_loss: 0.5803\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5607 - val_loss: 0.5795\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5600 - val_loss: 0.5788\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 0.5781\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5585 - val_loss: 0.5773\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5579 - val_loss: 0.5766\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5572 - val_loss: 0.5759\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5565 - val_loss: 0.5753\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5558 - val_loss: 0.5746\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5552 - val_loss: 0.5739\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5546 - val_loss: 0.5733\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 0.5727\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5534 - val_loss: 0.5720\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5528 - val_loss: 0.5715\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5523 - val_loss: 0.5710\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5517 - val_loss: 0.5703\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5512 - val_loss: 0.5696\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5507 - val_loss: 0.5691\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5502 - val_loss: 0.5687\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5497 - val_loss: 0.5681\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5492 - val_loss: 0.5677\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5487 - val_loss: 0.5672\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5482 - val_loss: 0.5668\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5478 - val_loss: 0.5663\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5473 - val_loss: 0.5658\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5469 - val_loss: 0.5653\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.5649\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 0.5644\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.5640\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5453 - val_loss: 0.5636\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5449 - val_loss: 0.5632\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5445 - val_loss: 0.5628\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5441 - val_loss: 0.5624\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5437 - val_loss: 0.5620\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 0.5616\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 0.5612\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 0.5609\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5424 - val_loss: 0.5605\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5421 - val_loss: 0.5601\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 0.5598\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5415 - val_loss: 0.5595\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.5592\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 0.5588\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.5585\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5402 - val_loss: 0.5582\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5399 - val_loss: 0.5579\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 0.5575\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 0.5573\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 0.5570\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 0.5568\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5386 - val_loss: 0.5565\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5383 - val_loss: 0.5563\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.5559\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 0.5557\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5377 - val_loss: 0.5554\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 0.5551\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 0.5549\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5370 - val_loss: 0.5547\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.5544\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5365 - val_loss: 0.5542\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5364 - val_loss: 0.5540\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.5538\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 0.5535\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5358 - val_loss: 0.5533\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.5531\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5354 - val_loss: 0.5529\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 0.5527\n",
      "121/121 [==============================] - 0s 873us/step - loss: 0.5155\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 6.7457 - val_loss: 7.8400\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.0315 - val_loss: 6.4506\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.7985 - val_loss: 5.4445\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9095 - val_loss: 4.7139\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2661 - val_loss: 4.1827\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8005 - val_loss: 3.7960\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4627 - val_loss: 3.5142\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2171 - val_loss: 3.3076\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0381 - val_loss: 3.1567\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9075 - val_loss: 3.0460\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8121 - val_loss: 2.9645\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7422 - val_loss: 2.9045\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6910 - val_loss: 2.8601\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6532 - val_loss: 2.8270\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 2.8023\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 2.7836\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5890 - val_loss: 2.7692\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5773 - val_loss: 2.7581\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5684 - val_loss: 2.7493\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5616 - val_loss: 2.7423\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5562 - val_loss: 2.7364\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 2.7315\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5485 - val_loss: 2.7274\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 2.7236\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5432 - val_loss: 2.7202\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 2.7171\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5393 - val_loss: 2.7143\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5377 - val_loss: 2.7115\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5362 - val_loss: 2.7088\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 2.7062\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 2.7038\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5324 - val_loss: 2.7012\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 2.6988\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 2.6964\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 2.6940\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 2.6916\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 2.6892\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 2.6867\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 2.6845\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 2.6821\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 2.6798\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 2.6773\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 2.6749\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5210 - val_loss: 2.6724\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 2.6701\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5194 - val_loss: 2.6677\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5187 - val_loss: 2.6654\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 2.6629\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5172 - val_loss: 2.6605\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 2.6580\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 2.6555\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 2.6531\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5145 - val_loss: 2.6507\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5139 - val_loss: 2.6483\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5133 - val_loss: 2.6458\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 2.6433\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5121 - val_loss: 2.6409\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5115 - val_loss: 2.6385\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 2.6360\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5104 - val_loss: 2.6337\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 2.6311\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 2.6287\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 2.6262\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 2.6237\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5078 - val_loss: 2.6213\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5073 - val_loss: 2.6187\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 2.6162\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 2.6137\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 2.6113\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 2.6088\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 2.6065\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5047 - val_loss: 2.6040\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 2.6015\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5038 - val_loss: 2.5991\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5035 - val_loss: 2.5966\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5031 - val_loss: 2.5941\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 2.5916\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 2.5892\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5020 - val_loss: 2.5867\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 2.5821\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5013 - val_loss: 2.5796\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5010 - val_loss: 2.5771\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5006 - val_loss: 2.5747\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 2.5723\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5000 - val_loss: 2.5699\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4997 - val_loss: 2.5674\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 2.5649\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4991 - val_loss: 2.5626\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4988 - val_loss: 2.5602\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 2.5578\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 2.5555\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 2.5509\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4978 - val_loss: 2.5485\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 2.5463\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4973 - val_loss: 2.5439\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 2.5415\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 2.5392\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 2.5368\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4964 - val_loss: 2.5345\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4961 - val_loss: 2.5323\n",
      "121/121 [==============================] - 0s 947us/step - loss: 2.0245\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d12669\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 5.7629 - val_loss: 4.9739\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.2286 - val_loss: 3.7172\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1737 - val_loss: 2.8372\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4395 - val_loss: 2.2165\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9239 - val_loss: 1.7759\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5592 - val_loss: 1.4616\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2998 - val_loss: 1.2364\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1141 - val_loss: 1.0744\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9807 - val_loss: 0.9572\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8839 - val_loss: 0.8719\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8137 - val_loss: 0.8101\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7625 - val_loss: 0.7648\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7249 - val_loss: 0.7315\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6971 - val_loss: 0.7067\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6764 - val_loss: 0.6881\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6607 - val_loss: 0.6741\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6488 - val_loss: 0.6633\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6396 - val_loss: 0.6549\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6325 - val_loss: 0.6483\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 0.6432\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6219 - val_loss: 0.6388\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6180 - val_loss: 0.6352\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6146 - val_loss: 0.6321\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6117 - val_loss: 0.6294\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6091 - val_loss: 0.6270\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6067 - val_loss: 0.6247\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6046 - val_loss: 0.6226\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6207\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 0.6189\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5989 - val_loss: 0.6172\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5972 - val_loss: 0.6157\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5955 - val_loss: 0.6141\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5939 - val_loss: 0.6125\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5924 - val_loss: 0.6111\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5908 - val_loss: 0.6095\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5894 - val_loss: 0.6081\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5880 - val_loss: 0.6067\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5866 - val_loss: 0.6055\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5853 - val_loss: 0.6041\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5840 - val_loss: 0.6028\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5827 - val_loss: 0.6015\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5814 - val_loss: 0.6003\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5802 - val_loss: 0.5991\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5790 - val_loss: 0.5980\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5779 - val_loss: 0.5968\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5767 - val_loss: 0.5957\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5756 - val_loss: 0.5945\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5745 - val_loss: 0.5934\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5734 - val_loss: 0.5923\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5724 - val_loss: 0.5914\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5714 - val_loss: 0.5903\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5704 - val_loss: 0.5894\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5695 - val_loss: 0.5884\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5685 - val_loss: 0.5875\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5675 - val_loss: 0.5866\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5666 - val_loss: 0.5857\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - val_loss: 0.5847\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - val_loss: 0.5838\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5640 - val_loss: 0.5830\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5632 - val_loss: 0.5821\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5624 - val_loss: 0.5813\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5616 - val_loss: 0.5805\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5608 - val_loss: 0.5797\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5600 - val_loss: 0.5790\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5593 - val_loss: 0.5783\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5585 - val_loss: 0.5775\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5579 - val_loss: 0.5768\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5571 - val_loss: 0.5762\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5565 - val_loss: 0.5755\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5558 - val_loss: 0.5748\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5551 - val_loss: 0.5742\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5545 - val_loss: 0.5735\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5538 - val_loss: 0.5728\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5533 - val_loss: 0.5723\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5526 - val_loss: 0.5716\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5520 - val_loss: 0.5710\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5515 - val_loss: 0.5705\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 0.5699\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5504 - val_loss: 0.5693\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5498 - val_loss: 0.5687\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5493 - val_loss: 0.5682\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5488 - val_loss: 0.5677\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 0.5672\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5478 - val_loss: 0.5666\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 0.5661\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 0.5657\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.5652\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5458 - val_loss: 0.5647\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 0.5642\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 0.5638\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5446 - val_loss: 0.5633\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5442 - val_loss: 0.5629\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.5625\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 0.5621\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5429 - val_loss: 0.5617\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 0.5613\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5422 - val_loss: 0.5609\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.5606\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5415 - val_loss: 0.5602\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.5599\n",
      "121/121 [==============================] - 0s 856us/step - loss: 0.5237\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4175 - val_loss: 0.7331\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6172 - val_loss: 0.6979\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5346 - val_loss: 0.5195\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4694 - val_loss: 0.4802\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4370 - val_loss: 0.4581\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4155 - val_loss: 0.4407\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4014 - val_loss: 0.4226\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3907 - val_loss: 0.4177\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3835 - val_loss: 0.4085\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.3966\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 0.3978\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3669 - val_loss: 0.3877\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3621 - val_loss: 0.3885\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.3860\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3560 - val_loss: 0.3850\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3516 - val_loss: 0.3875\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.3759\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3721\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3443 - val_loss: 0.3691\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3416 - val_loss: 0.3730\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3606\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3388 - val_loss: 0.3695\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3368 - val_loss: 0.3593\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3335 - val_loss: 0.3584\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3630\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3307 - val_loss: 0.3528\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3286 - val_loss: 0.3521\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3274 - val_loss: 0.3533\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3258 - val_loss: 0.3515\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3243 - val_loss: 0.3583\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3232 - val_loss: 0.3470\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.3488\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3203 - val_loss: 0.3454\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.3427\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3171 - val_loss: 0.3455\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3164 - val_loss: 0.3439\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3394\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3131 - val_loss: 0.3410\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3117 - val_loss: 0.3387\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3110 - val_loss: 0.3344\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3100 - val_loss: 0.3473\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3107 - val_loss: 0.3378\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3104 - val_loss: 0.3727\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3156 - val_loss: 0.3683\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3225 - val_loss: 0.4109\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3188 - val_loss: 0.3345\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3050 - val_loss: 0.3405\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3019 - val_loss: 0.3290\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3008 - val_loss: 0.3282\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2999 - val_loss: 0.3261\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2985 - val_loss: 0.3249\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2980 - val_loss: 0.3282\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2970 - val_loss: 0.3253\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.3232\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2952 - val_loss: 0.3247\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2932 - val_loss: 0.3255\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2928 - val_loss: 0.3228\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2921 - val_loss: 0.3227\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2914 - val_loss: 0.3184\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2902 - val_loss: 0.3246\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2896 - val_loss: 0.3176\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2884 - val_loss: 0.3199\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2884 - val_loss: 0.3173\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2891 - val_loss: 0.3180\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2863 - val_loss: 0.3180\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2854 - val_loss: 0.3240\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2846 - val_loss: 0.3153\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2837 - val_loss: 0.3150\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2836 - val_loss: 0.3113\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2823 - val_loss: 0.3137\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2820 - val_loss: 0.3109\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2813 - val_loss: 0.3122\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2816 - val_loss: 0.3157\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2795 - val_loss: 0.3110\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2797 - val_loss: 0.3126\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2792 - val_loss: 0.3130\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2784 - val_loss: 0.3065\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2785 - val_loss: 0.3107\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2784 - val_loss: 0.3088\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2769 - val_loss: 0.3108\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2761 - val_loss: 0.3117\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2764 - val_loss: 0.3028\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2761 - val_loss: 0.3094\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2741 - val_loss: 0.3062\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2749 - val_loss: 0.3082\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2736 - val_loss: 0.3053\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2731 - val_loss: 0.3100\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2725 - val_loss: 0.3030\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2716 - val_loss: 0.3117\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2723 - val_loss: 0.3003\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2702 - val_loss: 0.3112\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2704 - val_loss: 0.2994\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2700 - val_loss: 0.3099\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2697 - val_loss: 0.3017\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2693 - val_loss: 0.3081\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2689 - val_loss: 0.3027\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2701 - val_loss: 0.3502\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2775 - val_loss: 0.3267\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2760 - val_loss: 0.3372\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2726 - val_loss: 0.3031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020F710DBDC8>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020F723E4F88>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data = (X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0023840221939039176, 'n_hidden': 3, 'n_neurons': 61}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32505594690640766"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
