{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 12 - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows=500\n",
    "pd.options.display.max_columns=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) #matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) #scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy and Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatypes Exception code error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17004/308422390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1698\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1699\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1700\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    452\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\localEnv2\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "tf.constant(2.) + tf.constant(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.],[4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 1., 42.,  3.],\n",
       "       [ 4.,  5.,  6.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   3.],\n",
       "       [  4.,   5., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Huber loss Function implement (it already exists in Tf.keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAD8CAYAAACiqQeGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABE4ElEQVR4nO3dd3hUZfbA8e8JhF6VIEUQFUFZISBIERRQVATE7mKBtWLdBRULuhZ0bfizASoiKrrYUEQRUFEJRRRQFKkKWFiagvRQQ3J+f5wBQwjJhMzkzkzO53nmITNzc++5zGTO3HvPe15RVZxzzjkXG5KCDsA555xzf/HE7JxzzsUQT8zOOedcDPHE7JxzzsUQT8zOOedcDPHE7JxzzsUQT8zOxRER6SAiKiLVimh7V4hIelFsyzlnPDE7F2UiMkJExuXyeItQkq0XQFjOuRjlidk5h4iUCjoG55zxxOxcjMjtNLWI1As91iLH4q1FZI6I7BCR2SLSPMe6ThKRKSKyTURWisgLIlIp2/OTQ4/9n4isBaYXIM7rRGSpiOwK/XttLs8vDsW2VkQ+FZGSoecai8gXIrJZRLaIyA8i0rEg/0/OJTpPzM7Fp/8D7gRaAL8A40WkHFjyAyYCY4FU4HygKfBKjnVcDghwMtArnI2KyHnAEOAZ4HjgWeB5ETk79HwL4DlgANAQ6AR8km0VbwKrgZZAM+ABYEeY++xcsVAy6ACcKyY651JEVZgvxg+p6qcAInIlsAK4FBgO3A68o6pP7llYRG4AvheR6qq6JvTwr6p6WwG32w/4r6oOCd1fHDpavxP4CKgLbAXGquoWYBnwQ7bfPwL4P1X9MXR/aQG371zC8yNm54rGVOyoNfvt0kKs7+s9P6hqOjAPaBR6qDlwuYik77nx16nqo7OtY/ZBbPc49j/t/WW2bX+GJeNfReQNEfmHiFTMtuxTwHARmSQi94jIsQcRg3MJzROzc0Vjm6ouzX7DjnKzywr9K9keSz6IbSVhR85Ns91SgWOAOdmW23oQ6wbIbUo6BQgdJZ8AXAz8D+gP/CgitULPP4Al8Q+Ak4C5InLVQcbhXELyxOxc7Fgb+rdmtseaHmDZ1nt+EJHy2PXeRaGHvgP+lvOLQOi2vZAxLgLa5XisHbBwzx1V3a2qk1S1P9AEKA90y/b8ElUdpKpdgZeBawoZk3MJxa8xOxc7lgLLgQdE5C6gHvDvAyz771A19SrgPmAXVlgF8DgwQ0SGAi8CW4BjgbNV9bpCxvgE8K6IzMYKzDoDl2EFZohIN+x0+VRgPdARqAgsEpGyWNHau8BvwGFYUp9ZyJicSyiemJ2LEaqaISI9gOexgqk5wN3Afs1JgLuAJ7HK5wVAN1XdGlrPXBE5BfgPMAUogVVuj4lAjB+IyD+xIrBnsOvJN6rqR6FFNgLnYl8WygE/A9eo6rTQWOmqwGtADWBdaN/6FTYu5xKJqOZ2ucg555xzQfBrzM4551wMCTsxi0gJEfn+AD1/RUQGhboAzRWREyIbpnPOOVc8FOSIuQ9/VX3mdBY2FOMYoDfwQiHjcs4554qlsBKziBwOdMXGRubmHOB1NTOAKiJS8wDLOuecc+4Awj1ifga4g78aIORUGxvmsceK0GPOOeecK4B8h0uFxiWuUdXZItLhQIvl8th+5d4i0hs71U2ZMmWa161bN/xI40xWVhZJSXl/79m0KZkyZTIpXfpA33diVzj7F88Sdf+WL1+OqlLc//biWTzuX2amsHu3hPVZF4/7VxCLFy/+U1VT8lomnHHMbYHuItIFKANUEpGRqnp5tmVWAHWy3T8ca3ywD1UdBgwDaNiwof70009hbD4+TZ48mQ4dOuS73K5dIALJB9N4MUDh7l+8StT969ChAxs3bmTOnDlBhxI1ifra7RFv+7diBaSnw7FhdkWPt/0rKBFZlt8y+X4tUdX+qnq4qtYDegCTciRlsOnleoWqs1sDm1R19cEEXdz84x/wxRdBR+Gcc9Exdy6MHx90FPHloDt/icj1AKo6FJgAdMFaCm4DroxIdMXAq69CmTJBR+Gcc9HRpYvdXPgKlJhVdTIwOfTz0GyPK3BTJAMrLsqUgZdegpYtITU16Giccy5yXn0VVq2Ce+4JOpL44r2yY0CtWlCuXNBROOdcZP3977B+fdBRxB9PzDGga1fYuBE2b4ZKlYKOxjnnCu+HH2DnTjsb6AomcWvS48y993oRmHMucaxeDcvyrT92ufEj5hgxaJANm3LOuXiXkQGdOwcdRfzyI+YYIQJDh8KHHwYdiXPOFc7jj8OTTwYdRfzyI+YYctJJULVq0FE451zh9O8P27cHHUX88iPmGNKkCaj6dRnnXPwaNw6++goqVAg6kvjlR8wxZuxYqFYNjjgi6Eicc67gypTxpkmF5Yk5xtx8c9AROOfcwfnzT+jYEUqUCDqS+OansmPQSy/BE08EHYVzzhXMwIHw+utBRxH//Ig5Bp19NpQtG3QUzjlXMAMHQlb8zWIbc/yIOQbVqAErV8KMGUFH4pxz4Xn6afjyS0jgqZSLjP8Xxqjly+HXX4OOwjnnwtO6NdSrF3QUicFPZceoM8+0fzMyIDk52Ficcy4vixbZcM/y5YOOJDH4EXMMe/NNuPXWoKNwzrm8DR8Os2YFHUXiyPeIWUTKAFOB0qHl31PV+3Ms0wH4ENhz8vV9VX0wopEWQ+eeCxdeGHQUzjmXN2+/GVnhHDHvBE5V1VSgKdBZRFrnstw0VW0aunlSjoBy5WDxYnjttaAjcc653F1+OcyZE3QU8SHcivV8E7Oa9NDd5NBNDzqykBUryrJpU2HXkvjKlfOhU8652HXvvdCoUdBRxL6lS6FZs/CWFdX8c6yIlABmA/WB51T1zhzPdwBGAyuAVUA/VV2Qy3p6A73tXvPm9epN4dFH51Gjxo7woo0j6enpVIhQs1hV+PPPUqSk7IrI+iIhkvsXixJ1//r27UtmZiaDBw8OOpSoSdTXbo9Y2r8vv6xG06YbqFAhM2LrjKX9i5R58yrz738fz+bNyYDMVtUWef6CqoZ9A6oAacDxOR6vBFQI/dwFWJLfukqVaqagWr266owZmnDS0tIitq5Zs1TPPjtiq4uISO5fLErU/Wvfvr2mpqYGHUZUJeprt0es7F9Wlmrfvqrr1kV2vbGyf5EycqRqqVKqoHrWWarAt5pPfixQVbaqbgQmA51zPL5ZQ6e7VXUCkCwi1fJaV9262zj9dFizBjp0gHffLUgkxUuLFj5Ps3MutmRkWFORQw4JOpLYpAoPPGDX4HftsnkQxo4N73fzTcwikiIiVUI/lwU6AT/mWKaGiEjo55ah9a7Lc8NJyvjx0Ls37NgBF18Mjz5qO+P2JQIrVsC11wYdiXPOwe7d0LgxrF8fdCSxaccOuOwyGDDAOqENGgSDB0PJMDuHhLNYTeC10HXmJGCUqo4TkesBVHUocCFwg4jsBrYDPVTzT7HJyTB0KDRsCP36wd13WxXyiy9CqVLh7UBxUbOmfXlRtUTtnHNBKVkSvvkGKlUKOpLYs3YtnHceTJ9uc1K//TZ07VqwdYRTlT1XVZupahNVPV5DQ6FUdWgoKaOqQ1T1b6qaqqqtVfWrcAMQsSYa779vFcgjRsAZZ/g3sZxKlrRT/tOmBR2Jc644y8yEe+6B0qWDjiT2/PijtSadPh0OP9x6hxc0KUMMdf4691xLOrVqwZQptnNLlgQdVWzZsQOeecZOIznnXBB27oTatf2sZk5ffGF565dfoHlz64SWmnpw64qZxAxwwgkwc6btzJIltpNTpwYdVeyoWNHOLPgk5M65oKxbBzfe6JfUsnv5ZejcGTZtsoPMKVPs8uPBiqnEDH8d/nfrZqezO3Xyibez27nTBqmnp+e/rHPORdLq1dYm2OdcNllZcOedcM01dibz9tth9OjCT+YRc4kZ7IL5Bx9A375Wkv+Pf1h3GX8z2HWdDz+0/yPnnCtKNWvaPPE+5zJs2wYXXQQDB9pZzGHD7OdI/N/E7H9viRI2Ru655+zn//wHLr3UrrMWd3Xr2v/LrthpBOacS3C//mpHhn4K284ctG9vlxYrV4ZPPonscNaYTcx73HgjjBtn11ffeQdOPdWakhRnIrBxI95r3DlXZKpXh6uuCjqK4M2dC61awbffwpFHwtdf2yXXSIr5xAx2UX36dDtS/Ppr+09ZuDDoqIK1Z7iCn953zkXbunUwbx6cdFLQkQRrwgRo2xaWL4c2bey0/nHHRX47cZGYwbrMzJwJLVvCb7/Zf8pnnwUdVbAuuAC+/z7oKJxzie7nn+Hjj4OOIljPPQdnn22Ftz16wKRJdhYhGuImMQPUqAFpaVYVuHkznHWWXXAvrsaPt/FyzjkXLVlZdkA0YEDQkQQjMxP69LFe11lZcN998OabUKZM9LYZV4kZrDvYO+9A//72H3bdddbOMzNys47FjVKl4Nln7TS/c85Fw7BhloyKoy1b4JxzrNd1crIN3R0wIPoFcGG21I4tSUnwyCNwzDE2CcaTT9ok1G+8UfjxY/GmRQu79u6cc9FwzTXFs9B0+XI7df3DDzaD1pgxcMopRbPtuDtizu7KK2HiRKha1cb2nnIKrFoVdFRFq21bG062bFnQkTjnEs348TZZxaGHBh1J0Zo924qMf/gBGjSw+qaiSsoQ54kZoGNHq9Q++mj47ju7FjJnTtBRFa0xY7x1qXMu8kqUKH4tgD/4wJLw6tU2cdDXX0P9+kUbQ9wnZrBpI2fMgJNPhpUroV07G/tcXNx0E/Ts6XNZO+ciZ/Vqm+mvZcugIykaqvB//wfnn29dva64Aj791E5jF7WESMwA1arZ8KnLL4etW+2C/bPPFp9kNWYM3HZb0FE45xLFPfdYYioOMjLg+uut17Wq1TC98kpwM2jlW/wlImWAqUDp0PLvqer9OZYR4FmgC7ANuEJVv4t8uHkrXdqq5ho0sCrCvn1h8WJL0CXjsswtfB07Wos455yLhJdfDjqCorFxo/W8/vxzGwL1+ut2P0jhHDHvBE5V1VSgKdBZRFrnWOYs4JjQrTfwQiSDLAgRm/DizTctUT//vFXWbd4cVERFo0oVG/j+7rtBR+Kci3e9e1tTkUTvi/3rr9bN7PPPrVnI5MnBJ2UIIzGr2TPJYHLolvME8TnA66FlZwBVRKQQs1EW3iWXWGeWlBRrMN62bfGoXF65MugInHPx7rLL4Igjgo4iuva0d160CP72N6u8btUq6KiMaBgXYUWkBDAbqA88p6p35nh+HPCYqn4Zuv8FcKeqfptjud7YETUpKSnNR40aFZGdyMuqVWW4++7GLFtWnqpVd/Gf/8yjUaMtUd9ueno6FQKamzE9vSQVKuyO8jaC27+ikKj717dvXzIzMxk8eHDQoURNor52e0R7/2bNOoRmzTaQnBxMgU5RvH6TJlXnsceOJSMjiRYt1nP//QuoUKFoulR17Nhxtqq2yHMhVQ37BlQB0oDjczw+HmiX7f4XQPO81tWgQQMtKhs2qHbqpAqqZcqovvtu9LeZlpYW/Y3kYtky1aZNVbOyorudoPavqCTq/rVv315TU1ODDiOqEvW12yOa+7drl+oll6hu3Rq1TeQrmvuXlaX60EOWC0D1+utVMzKitrlcAd9qPrm2QFXZqroRmAx0zvHUCqBOtvuHAzHT6qNKFZsV5NprbT7niy6CRx9NzIrtunVh1qzEvzbknIs8EavPKVcu6Egib+dO+Mc/rAZJBJ5+2mqQYrEwON/ELCIpIlIl9HNZoBPwY47FxgK9xLQGNqnq6kgHWxjJyfDii/DEE/ai3H03XH017NoVdGSRl5Vlw8Z27Ag6EudcvFi92ibFScSpZNetg9NPh//+1750fPCBjdqJ1QOYcI6YawJpIjIX+Ab4TFXHicj1InJ9aJkJwC/AUuAl4MaoRFtIIjbhxejRULYsvPoqnHkmrF8fdGSRVbo0XHqp9RR3zrlw1KxpBbOJ9rmxeDG0bg3TpkGtWvZv9+5BR5W3cKqy56pqM1VtoqrHq+qDoceHqurQ0M+qqjep6tGq2lhzFH3FmvPOsxenZk0rj2/TxibBSCRduljV4c6dQUfinIt1P/9s/R4SrSf2lCmWlJcuhWbN7DLfCScEHVX+Euy7UfiaN7fy+NRU+0bVqpUl60Ty7rvw229BR+Gci3XJyVCnTv7LxZMRI+z09YYN1sti6lSoXTvoqMJTbBMz2Btx2jTo2tVOZ3fqBCNHBh1V5AwZYl3QiuNc1c658Pzxh02Xe/75QUcSGVlZ1k70yiut1eYtt1jL4ngaQVesEzNAxYo2ZWSfPlYI1rOntfNMlIrtW26Bt98OOgrnXKyaOBFeCKxXY2Rt327NpR55xGbFev55eOqp+JshKwYLxYteiRLwzDNwzDHwr3/BQw/ZNYlXXrHeqfHs3nttvmrnnMtNz55BRxAZf/xhkxfNnGkHXO++a8W98ajYHzFnd9NNNl1kxYrw1ltw6qmwdm3QURXOoYfa6foPPgg6EudcrOnXD8aPDzqKwluwwOqEZs60Xg5ffRW/SRk8Me/nrLNg+nR7cff0Ul24MOioCqdCBahcOegonHOx5tZbbRKHeDZxou3DsmU2d/TMmXD88UFHVTiemHPRuLG9uCeeuO/sI/GqeXM4+WQbEuGccwDvvGOX8eL5UtfQoTY0dPNm6+g4eTLUqBF0VIXnifkAatSwF/mCC2DTJujcGV56KeioDt7MmfDgg0FH4ZyLFT/9FLudr/KTmWlH+zfcYD/3729FrmXLBh1ZZHhizkO5cjBqFNx1l734vXvD7bfHZ8u6tm3htdeCjsI5Fws2bLDRJ9WrBx1JwaWn29Cup5+28devvGJV2InUsSyBdiU6kpJswouXX7Zm5//3f3YUvXVr0JEV3B9/2IB7H9fsXPG1c6d1w0pPDzqSglu5Ek45BcaOtVPwEyfaeOVE44k5TFddZW+CKlWswrl9e1gVM/Nnhad6dXjyyfgb0+eci5zSpWH+/PhquAHw/fdW3PX993D00Vac26FD0FFFhyfmAujYEWbMsDfF7NlWsf3DD0FHFT4RK2x74QXvoe1ccfTLLzb9bXJy0JEUzEcfWQHrqlX274wZ0LBh0FFFjyfmAmrY0N4U7drBihV27TaexgGK2PWljRuDjsQ5V9Rq1LA5ieOFqjV/Ouccu3x4+eXw2WdQrVrQkUWXJ+aDUK2aDZ+6/HJ7s3TvDoMGxU8bz7vvturFbduCjsQ5V1SWLoVFi+ygIh7s3m1Nn265xT5bH3wQXn/dTsUnOk/MB6l0aXuTDBhgVdp9+sA//2lvpnhw223wxRdBR+GcKyq//ALffRd0FOHZvBm6dbPLbqVLw5tvWnvheB3eVVD59soWkTrA60ANIAsYpqrP5limA/Ah8Gvooff3zNucyERsyEH9+lYZ+Nxz1sTjnXeCjix/L76YWMMLnHMHtnUrnHFG0FGE5/ffS9O2rRWoVatmkwzFe3eyggrno3k3cJuqHge0Bm4SkUa5LDdNVZuGbgmflLO79FKYNMneRJ98Ytedf/89ts+3JCVZdfljjwUdiXMu2vr0gfffDzqK/M2cCTfe2Jz58+HYY+1+cUvKEMYRs6quBlaHft4iIouA2kCcd5COrLZt7U3Utat907vxxuYcdZSV98eqli2hadOgo3DORVs8TOv43ns209WOHaU47TS7X6VK0FEFQ7QAFUsiUg+YChyvqpuzPd4BGA2sAFYB/VR1QS6/3xvoDZCSktJ81KhRhQg9NqWnl+T++//Gd99VpVSpTO6++0fat4/dKao2bSrJvHlVaNfuzwL9Xnp6OhXibSBkASTq/vXt25fMzEwGDx4cdChRk6iv3R4F2T9VGDy4Ppde+j+qVdsV5cgOjiq8+WZdhg8/CoAzzvgft9/+KyVLxkk1bQF17Nhxtqq2yHMhVQ3rBlQAZgPn5/JcJaBC6OcuwJL81tegQQNNVLt2qXbtulLtLaf62GOqWVlBR5W7VatU77qr4L+XlpYW8VhiSaLuX/v27TU1NTXoMKIqUV+7PQqyf1lZqmPGqGZkRC2cQtm5U/XKK+1zUkR14EDVSZPSAo4quoBvNZ/8GFb5j4gkY0fEb6jqflcqVHWzqqaHfp4AJItIgo80O7DkZLjttsUMHGgFYnfdBddcA7ti8AtrzZrWcnTTpqAjcc5FkqqN+T3nHGsnHGvWr7c5k1991YZvjh5tcxEUl8rrvOSbmEVEgJeBRar61AGWqRFaDhFpGVrvukgGGm9E7E02erS96V55xWao2rAh6Mj2t3OnXW/esiXoSJxzkbJ2LYwcGZv9FZYuhTZt/pqmcepUOO+8oKOKHeEcMbcFegKnisic0K2LiFwvIteHlrkQmC8iPwCDgB6hQ/Zi77zz7E1XowakpdmbcenSoKPaV+nSMG8eVKwYdCTOuUjIzIRDDrFeC7E2LHLaNGtnvHgxNGkCs2ZBi7yvuBY7+b5kqvqlqoqqNtG/hkNNUNWhqjo0tMwQVf2bqqaqamtV/Sr6ocePFi3szdekic2B2ro1fPll0FHtq1QpO8KfPTvoSJxzhTV+vPXEjjUjR0KnTnYau0sX+xysUyfoqGJPjH2XSlx16tibsEsXWLcOTjvN3qSx5KKL4Jhjgo7COVdYZ58Nzz6b/3JFRRXuv9+GQ+3aZV0SP/zQz9IdiCfmIlSxor0Z//Uve3P27Glv1lg56d+ypc13OmNG0JE45w7W0KF27bZSpaAjMTt2wGWXWa/rpCSbV2DQoNgsSIsVnpiLWMmS9k128GB7kz74oL1pd+wIOjKzbJn11HXOxadmzaBevaCjMGvX2tnBt96y+Z8/+siOll3e/DtLQG6+GY46Cv7+d3vTLltmLTJTUoKNq3Nn+3fdOjj00GBjcc4VzKRJ1sKyTJmgI7GZrLp2hV9/tUt548ZZnY3Lnx8xB6hLF5g+3d60X31llYqLFgUdlVWNd+sWO6fYnXP5U4URI2Jj2OMXX9gIlF9/hebNrV2xJ+XweWIOWJMm9qY98UR7E7dpE/x0jPXr25AGH+jvXPzYudOGRwV91m34cDvztmmTDRedMsUaGbnweWKOATVrWrHGBRfYm7lzZ3jppWBjSkqyP6rffw82Dudc/n77zSbSCfIsV1YW3HmnDdPavRvuuMMmoihfPriY4pUn5hhRrhyMGmVv7N27oXdve2NnZQUTT1KStRKtVmwbqzoXP+rVsy/3QZ3l2rbNhlsOHGgFrsOGweOPx15zk3jh/20xJCnJ5kcePtze3E88ARdeaJOcB6FVKzsN9dNPwWzfOZe/MWPg5ZeDGxO8ejW0b2/zPVeubHPSx2Jzk3jiiTkGXX01fPqpzUU6Zoy96VetCiaWVausQts5F5tOOCG4lpZz59oX+G+/hSOPhK+/tuFRrnA8MceoU0+1N/lRR1mbzFat4Icfij6Onj2thahfa3Yu9kycaNdwU1OLftsTJth17eXLbYjWzJlw3HFFH0ci8sQcw4491t7sbdvCihXQrp31wC1qn34K99xT9Nt1zuVt2jTYuLHotztkiLX9TE+HSy6xkSRBV4MnEk/MMa5aNfj8c7j0Uvsj6N7duoYVpVioEnfO7Wv9enjoIRveWFQyM62l8D//aYWp990Hb7wRGw1NEokn5jhQpoxNePHAA/bHsOcPY/fuotm+iLUMbdcuuEI059xf1q+Hk0+GjIyi2+aWLXDOOXZgUKoU/Pe/MGCA9zuIhnwTs4jUEZE0EVkkIgtEpE8uy4iIDBKRpSIyV0ROiE64xZeITXgxcqT9UQwZYkfPmzcXzfbLlbOjZh+T6FzwDjkE5syB5OSi2d7y5X9dSjv0UDuLd/nlRbPt4iicI+bdwG2qehzQGrhJRBrlWOYs4JjQrTfwQkSjdHtddpn1w61WDT7+2P5Y/ve/otn2ccfBa6/Bjz8Wzfacc/v78stqPPhg0SXlb7+1mefmzoUGDWz2uZNPLpptF1f5JmZVXa2q34V+3gIsAmrnWOwc4HU1M4AqIuJN2KKkbVv74zj2WJg3z/5ovvmmaLZdoULRbMc5l7sTTtjA3/9eNNsaMwZOOcVGZXToYCNFivKadnFVoGvMIlIPaAbMzPFUbWB5tvsr2D95uwg6+mib+OLUU+GPP/4a4B9tF1wAdevC//5XLvobc87t4403YOPGZBo2jO52VK3B0QUXwPbtcOWVNjrjkEOiu11nwp72UUQqAKOBvqqa88pmbpf/9+vaKiK9sVPdpKSkMHny5PAjjTPp6elFsn/9+wtlyjRgwoSaXHAB9O79Mz16LI9qQcasWYcwa9Yh1K07OXobCVhRvX5FbePGjWRmZibkvu2RqK8dwOzZtWjcOLr7t3u38MwzxzB+fC0Arr32Fy655H989VXUNrmPRH79wqaq+d6AZOBT4NYDPP8icEm2+z8BNfNaZ4MGDTSRpaWlFdm2srJUBw5Ute+5qldfrbpzZ3S3mZaWFvVtBKkoX7+i1L59e01NTQ06jKhK1Ndu3jz7N5r7t2GD6mmn2edImTKqo0ZFbVMHlKiv3x7At5pPzg2nKluAl4FFqvrUARYbC/QKVWe3Bjap6urCfmlw4RGB22+H0aOhbFnrm3vWWbBhQ/S2uXNnEqmpsTH3q3OJ7s8/bZhkNIdI/vLLX9POHnaYTYpx0UXR2547sHCuMbcFegKnisic0K2LiFwvIteHlpkA/AIsBV4CboxOuC4v559vk07UqGGV223awM8/R2dbpUtn8dVXwTXOd664yMy0IUqTJtnkNtHw1VfWevfHH+Fvf7OOg61aRWdbLn/5vsyq+iW5X0POvowCN0UqKHfwTjzR/qi6dbOK7Vat4IMPbFhVpFWtCk8/bX/IZ5wR+fU752DECPuC/cgj0Vn/W29ZcdfOnXDmmfDOOzZLlAuOd/5KQHXrwpdf2unsdetstpc33ojOtk45BZo0ic66nXNwxRXQr1/k16tqLT0vvdSS8g03wLhxnpRjgSfmBFWpEowdCzffDLt2WZeeBx6wP8ZIat7crnGPHRvZ9Trn4JZb4LffIj9MaedO+Mc/rNe1iJ35eu656J0qdwXjiTmBlSxpfW0HDYKkJOtre/nl1vc6krZvt65AzrnIOuMMOPzwyK7zzz/h9NOt13X58vDhh9C3r/e8jiWemIuBf/7TjmgrVIA334ROnWDt2sitv149+Pe/raoz0kfkzhVHW7fa3+pZZ0Hp0pFb708/WZHXtGlQq5b9e/bZkVu/iwxPzMVE16523fnww2H69L8qMCNFFa6+GpYti9w6nSuu1q6N/IiKyZP/GqnRrBnMmmX/utjjibkYSU21P8bmze3otnVrG7MYCSI2nKNePRve4Zw7OKtW2ZDHe++N3DpffdVOi2/YYLPSTZ0Ktb1pcszyxFzM1KxpY53POw82bYLOnWH48MisW8TWdf/9kVmfc8XRsGHw9tuRWVdWFtx9N1x1lc3dfOut1lPfJ6OJbV6DVwyVLw/vvQf9+8PAgXDttbBkCTz6qBWJFcbFF3tlp3MHKzMzcqMntm+3yut334USJWwO9+uvz//3XPD8iLmYSkqCxx+Hl16yRDpwoLXf27atcOutVMm+me/5hu6cC8/WrdC0qf0NFrZC+o8/oGNHS8qVKsGECZ6U44kn5mLummvgk0+sqcD779v0kasL2eW8UiU7VV6iRGRidK44KF/eaj7KFXJG1fnzrePfzJlwxBFW7Omd+eKLJ2bHaafZBOhHHQXffmt/1D/8cPDrE7EhGJ9/bqfInXN5e/99u7ZcvXrh1vPpp9C2rY2O2JOcjz8+MjG6ouOJ2QFw3HEwYwacdBIsX269tSdMKNw6f//dWoI65/LWsqWNkiiMF16wYZGbN9tlqbQ0myXKxR9PzG6vlBQ7lXbppZCebke9Q4Yc/Pp69bIPnHnzIhejc4nmlVfsNPbB9pzPzLRq6xtvtJ/vvtuqusuWjWycruh4Ynb7KFMGRo60IU9ZWdY1rDDzwP72m43H9I5gzu1P1U47H2w9Rnq6Tff69NOQnGzjlR9+uPCjK1yw/OVz+xGxIRsjR0KpUtZv+5xzYMuWgq/rqKNs2snt2z05O5fdli3WInPAACuYLKiVK212t7FjbQrWiRNtJioX//JNzCLyioisEZH5B3i+g4hsEpE5odt9kQ/TBeGyy+zU9qGH2vXmdu3gf/87uHX16mUtAZ1zZvZsG654ML7/3i4Tff891K9v9SEdOkQ0PBegcFpBjACGAK/nscw0Ve0WkYhcTGnXzio7u3a1GaRatYKPPir4el57za6jOedg40ZLpAeTTKdPP5RHHrHxziefbBXd1apFOEAXqHyPmFV1KrC+CGJxMeroo204VceOVml9yikwdWrBPgnKl7dv9z17RilI5+LIOefAwoUF+x1Vu5Z8773Hs22b/S199pkn5UQkGsaFPxGpB4xT1f1GxIlIB2A0sAJYBfRT1QUHWE9voDdASkpK81GjRh1s3DEvPT2dCgnWkDYjQ3j66QZ8/HFNAHr3/pkePZaH3aVo925h5cqyHHFEIduLFYFEfP0A+vbtS2ZmJoMHDw46lKiJ9ddO1f6WSpUKv+giM1MYNKg+Y8fazBNXXfUrl1++LCHnUI7116+wOnbsOFtVW+S5kKrmewPqAfMP8FwloELo5y7AknDW2aBBA01kaWlpQYcQFVlZqo89pmofL6rXXKO6a1fB1jFggOqSJdGJL1IS9fVr3769pqamBh1GVMXyazd1qmqvXgX7nY0bVc84w/7eSpdWvffeBdEJLkbE8usXCcC3mk9+LPR0A6q6OdvPE0TkeRGppqp/FnbdLvaIwJ13wo4d83nsseMZPtymkHzvPasMDUfz5tYC1Lni5qSToE6d8Jf/7Tfo1g0WLLA+Ax9+CDt3rgEaRStEFwMKPVxKRGqI2AkVEWkZWqf3e0pw7dv/yZQp1llo0iT7wAl3YveuXW2M9PvvRzdG52LJrbfa30i9euEtP3OmFVsuWGCd+WbOhDZtohqiixHhDJd6C/gaaCgiK0TkahG5XkT2zFVyITBfRH4ABgE9QofrLsG1bAmzZkHjxvDjj9ZScPr08H53xw5YtCi68TkXS848E+rWDW/Zd9+1iu01a6BTJ/jqKzjyyKiG52JIvqeyVfWSfJ4fgg2ncsVQ3brw5ZfQowd8/DGceqp1H7r00rx/74gj4J57bLKMhg2t45hziejXX2HaNBvLnx9VeOwxa6sJNlf6c89ZVy9XfMTslPabN29mzZo1ZMTppL6VK1dmUQIfEubcv2efTebkk6tz992VuOwym1Xqvvvyn1d26FCbu/nEE6McsHMB2bUrvJabu3bBddfBiBH2d/PEE3b6OxErr13eYjIxb968mT/++IPatWtTtmxZJA7fmVu2bKFixYpBhxE12fdPVdm+fTsXXriS2rXhyisr8cADlpyHD8/7aPiFF+zf33+HGjWiH7dzRenzz61JT8OGeS+3fr31vJ4yxeZjfuMNOPfcIgnRxaCY7JW9Zs0aateuTbly5eIyKRc3IkK5cuWoXbs2J520hrFjoUIF+3Dp1AnWrs3793/6yU6Fe2WCSySqMGoU/JnP+JQlS6yoa8oUqFkTpk71pFzcxWRizsjIoKzPWRZ3ypYtS0ZGBl272nXnww+3YrDWra047EAaNrSe3Lt3W7W2c/Fu0yY7CzRsmP0dHMi0afb3sXgxpKZa5XXz5kUXp4tNMZmYAT9SjkPZX7PUVKvYbt7cxjm3aWPDqg6kRAno2xdGj45+nM5F2+ef26xsefnvf+G00+w0dteulqQLMsbZJa6YTcwu/tWsaafnzj3XmvafeSa8/PKBl3/4YbjwQj+l7eLb+vVwwQX2fs6NqhVG9uoFGRk23/mHH0ICl6S4AvLE7KKqfHk7Cr79djtVfc01cNdduZ+yrlIFNmyw8Zu7dhV1pM4V3vbtNsnL5s25V1Pv2GHTqT70ECQl2VH1s8+GV7Xtig9PzC7qkpJg4EC73layJDz+OFx8sU1bl9Mhh8CLL0KpUkUfp3OFsXu3jUD47juoVGn/59eutXH+b71lxZHjxsHNNxd9nC72eWKOsA4dOnBzIf/aIrGO/GzYsIHDDjuMn8Poo3nhhRfy1FNPFXqb115rTUgqV7aj6A4dYPXq/Zc79ljrvf3cc4XepHNF5sEHbXhgbl8qFy2y9ppff23XkadPh7POKvoYXXzwxFxMPfLII3Tp0oWjjz4632Xvv/9+/vOf/7Bp06ZCb7dTJ/twOvJI+OYb+7CaN2//5U480a5JOxcPVG1yl0ty6ZP4+edW/Pjrr/a+njkTmjQp+hhd/PDEXIzsCl243bZtG8OHD+fqq68O6/caN27MUUcdxciRIyMSx3HHwYwZ9mG1fDm0bWtH0tkdcQQcfbR92OU3DtS5IC1ZAl26WGOQnNMIv/QSdO5sw6cuuAAmT7aiSOfy4ok5CrKyshgwYADVqlWjevXq9OvXj6xQtVNup6mvuOIKunXrts9ju3fvpk+fPlStWpWqVaty++23710HWLetgQMHcvTRR1O2bFkaN268X+Ls0KEDN9xwA/369SMlJYW2bdsCMGHCBJKSkvbeBxg4cCAist/tvvvuA6B79+689dZbEfs/ql7dhk/16AFbttjUdjlPXYtAs2ZQunTENutcxNWvD4MG7VvslZUFd9wBvXtDZqZ9wRw1ypK3c/mJm8QsEsztYLzxxhuUKFGCr776iiFDhvDMM8/wzjvvFHgdWVlZfP3117z44osMGzaMZ555Zu/z//73v3n55Zd57rnnWLhwIf379+e6665j/Pjx+6xn5MiRqCrTpk3j9ddfB2DatGk0b958n3HHN9xwA6tXr957u+2226hRowa9Qp33W7ZsyaxZs9i+ffvB/afkokwZePNNGzqSlWWFMH362AfZHj162NHGiy9GbLPORcwVV1jnumOO+euxrVtt2N8TT1ix4/DhNjFFUtx82rqgxWSv7HjXqFEj/v3vf1OxYkUaNGjASy+9xBdffMEluV2AOoCaNWsyaNAgRIRjjz2WxYsX89RTT3HrrbeydetWnnrqKSZOnMjJJ58MwJFHHsmsWbN47rnn6Nq16971HHnkkTz55JP7rHvZsmXUzHE+rWLFint7Xz/++OO89dZbTJ48mfr16wNQq1YtMjIyWLVqVVjXpcMlAgMG2Afb1VfbkcfPP1vl6p5xnaVLW8Wrc7HmxhvtiHmPVauge3eYPduG/40ebZXYzhVE3HyHUw3mdjCa5KjsqFWrFmvWrCnQOlq3br3PEW2bNm1YuXIlmzdvZuHChezYsYPOnTtToUKFvbcXXnhhvyrr5rn099u+fTtlDjCzxKOPPsqgQYNIS0ujYbbO+3tapEbyiDm7yy+3IplDD4Xx463x//Ll9lxKCtx0k12fW7AgKpt3rkDGjbMj4ZYt7agYbArTVq0sKR91lBU5elJ2ByPfI2YReQXoBqxR1eNzeV6AZ4EuwDbgClX9LtKBxpPkHJOnisje68NJSUlojoxf0Kkt96zro48+om6Omddzbrt8+fL7/X61atXYsGHDfo8//PDDDB06lClTpuw9Ut5j/fr1AKSkpBQo1oI4+WQrCuvaFebOtQ+9jz6CFi3s+d9/9ynwXGxo3Bhq1frr/vjxdtklPd2KGceMsS+Uzh2McI6YRwCd83j+LOCY0K038ELhw0pcKSkprM4xePeHH37Yb7mZM2fuk8BnzJhBrVq1qFSpEo0aNaJ06dIsW7aM+vXr73M74ogj8o2hWbNmLFy4cJ/HHnroIV588cV9Tl9nN3/+fGrVqsVhhx0W7q4elPr17UijY0dLxKecYh9yYB98p5xipwezX4d2rqisW2dzJNepAyecYI8NHmynr9PT4dJL7cyPJ2VXGPkmZlWdCqzPY5FzgNfVzACqiIgPCDiAU089lY8//pixY8fy008/ceutt7J8zznbbFatWkXfvn356aefeO+993jiiSe45ZZbALse3K9fP/r168crr7zC0qVLmTNnDkOHDmXYsGH5xnDmmWeyaNEi1q1bB9iR8rPPPsvbb79N+fLl+f333/n999/ZsWPH3t+ZNm0anTvn9f0scg45BD75BK680locXnCBFdKoWkL+4gvrve1cUStXzk5XJyVZ3cM//2m9rrOy4IEHYOTIvOcfdy4ckSj+qg1kzywrQo/t19NJRHpjR9WkpKQwefLkXFdYuXJltmzZEoHQil5mZia7du0iMzNz7z5kZGSwe/dutmzZwkUXXcS3337LlVdeCcA111xDt27dWLdu3d7lMzMzufjii9m+fTutWrVCROjZsyfXXHPN3mXuuOMOKleuzMCBA7nhhhuoWLEiTZo0oU+fPvusZ9euXfv9X9arV4/mzZszYsQIrr32WgYOHMjmzZv3GT4FMHbsWDp06MCOHTsYM2YM77///j7rzu012rFjxwFf14Lq2RNKlqzLSy8dxR13wJQpq+jbdwkXX6x8800SCxZUonnzjRHZVk7p6ekR249YsnHjRjIzMxNy3/aI1mv31lt1OO20NRx22E4mTCjBgw82YubMQ0lOzuL223+kffs1TJkS8c3uJ1Hfm3sk+v6FRVXzvQH1gPkHeG480C7b/S+A5vmts0GDBnogCxcuPOBz8WLz5s1Bh5Cnjz/+WBs0aKC7d+/Od9khQ4bo6aefvs9jB9q/aLx2776rWqaMleOddprqhg2qS5ao/vOfEd/UXmlpadFbeYDat2+vqampQYcRVdF47bKyVF99VXXTJtVly1QbN7b346GHqk6bFvHN5SlR35t7JPr+Ad9qPvkxElXZK4Dss4geDqyKwHpdFHXu3JmbbrqJFStW5LtscnIyg/ObXDaKLrzQpo887DA7jd2mjZ1KHDTI2hwuWRJYaK4Y+PRTe99dcQUsXvxXG9mGDa29Zrt2QUfoEk0kTmWPBW4WkbeBVsAmVc1lagIXa/71r3+FtVzv3r2jHEn+Wra0D8Fu3WD+fPtw/PBDS8pJSfs2eHAuksqVs2kZ33/fhvVt327FiaNHQ9WqQUfnElG+R8wi8hbwNdBQRFaIyNUicr2IXB9aZALwC7AUeAm4MWrRumLtiCNsVp7Ona1/9qmn2kw+PXvCl1/aXLfORcry5TZXcrt29v664AJLylddZcWJnpRdtOR7xKyqebarCp0zvyliETmXh0qVbGxznz7w/PM2PGXJEvjjD6vmbtQo6AhdoihZ0qYo7d3bmomAtda84w4fT++iK246fzm3R8mSMGQIPPOMfUDefz9s3mzdliZMOPiObc4BZGTY3MqqNvxp+HAbAvXeezYZhSdlF23eK9vFJRE7aj7qKJsDd+RI67Fdpw60bw+5NDxzLmyZmXap5KefrOhw7Firc3CuKHhidnHt7LPt+l+3btYxbM0a+zBduxbOPDPo6Fy8eeghuxzy/PNWx9C4sV06CaOhnnMR46eyXdxr2hRmzbIWiT//DB06wIgRAQfl4tKff1rdwp9/WpHhl196UnZFzxOzSwi1asHUqXDOObBli10PfOQRSEsLOjIXD55/Hnr1srHxu3bZdI4ffWTFhs4VNU/MLmGUL29jS/v1sz7G99wDTz1lfYydO5CdOy0J//e/Nib+2WetuLCkX+hzAfHE7BJKiRI24cWLL9rP48bZNHzTpgUdmYtFI0fCscfauOTy5a1pzb/+5ZXXLliemCOse/fuVK1alZ49ewYdSrHWuzd8/LGNQ50xA264waaRdG6PH3+Ee++F336D2rX/KiJ0LmiemCPslltu4fXXXy/w7y1fvpwOHTrQqFEjUlNTef/996MQXfFy+unw1VdQrx4sWGBHRh98EHRULhYMGQJNmlhSPuEEKx5s2jToqJwznpgjrGPHjlSsWLHAv1eyZEmeeeYZFi5cyGeffUafPn3Ytm1bFCIsXho1sh7bbdrApk3WvvOTT4KOygVp2DDo29caiZxzjhUN1qoVdFTO/cUTc4yoWbMmTUNf2atXr07VqlX5888/gw0qQVSvDpMmQY8ekJ4OZ50FAwYEHZUrallZVm193XXWQKRfPysW9GY0LtZ4Yo5B3377LRkZGdSpUyf/hV1YypSBN96wa4oADzxgRT6ZmYGG5YrI9u3WjOaFF6zy+sUXrUiwRImgI3Nuf56YY8y6devo1asXL7/8MuKloRGVlGQ9kF9/3YbCDB5sR89btgQdmYum33+3yvwJE6BiRbuUEQMzmTp3QJ6Yi9DAgQMRkf1u9913HwA7d+7kvPPOo3///px00kkBR5u4eva0ie+rVIHPPrO5nZcvDzoqFw3z5lmR1/ffWwevGTOsKNC5WOaJOcI6derERRddxMSJEzn88MP5+uuv9z53ww03sHr16r232267jRo1atCrVy9UlSuuuIJTTz3Vh1oVgVNOgW++gfr1YdEiOPFEmD076KhcJH36KZx0kvVNP/FEq7z2aUFdPAgrMYtIZxH5SUSWishduTzfQUQ2icic0O2+yIcaHz7//HPWrl3LH3/8wYoVK2jTps3e5ypWrEiNGjWoUaMGr732Gm+99RaTJ0+mfv36TJ8+nXfeeYcPPviApk2b0rRpU+bNmxfgniS++vWtYrt9e5vP+aSTYMyYoKNykTBokF2mSE+Hv/8dpkyxIkDn4kG+TedEpATwHHA6sAL4RkTGqurCHItOU1Ufnh+GRx99lCFDhpCWlkaDBg0AaNeuHVneO7LIHXIITJwIV11lxWHnn29FQc2bBx2ZOxiZmTBkyNGMHm3377oLHn7Y6gucixfhvF1bAktV9RdV3QW8DZwT3bBy98ADdgNo0AAWL7bTj3s+RG+7DZ580n6uVQtWrYLJk222IbCCj2HD7OeKFa3o56OPrFoTbFaZN9+0nw+m7ir7deNKlSrtdy0Z4OGHH+b5559nypQpe5OyC1apUtYn+ZFH7P7tt8PAgQ3IyAg2Llcw6enQvTuMHl2HkiXhtdfg0Uc9Kbv4I6qa9wIiFwKdVfWa0P2eQCtVvTnbMh2A0dgR9Sqgn6ouyGVdvYHeACkpKc1HjRqV6zYrV65M/fr1D2J3grVixQp69+7N2rVrKVmyJP3796d79+57n3/88cd57bXXGDduHEcddVSAkRZeZmYmJXIZa7J06VI2bdoUQESRMWlSCq8/XIHMrCSqn1CeAQMWUqHC7qDDipi+ffuSmZnJ4MGDgw4lolatKkP//o3J+t96ypbJ4KbHNpGaGr/vw7ykp6dToUKFoMOImkTfv44dO85W1RZ5LqSqed6Ai4Dh2e73BAbnWKYSUCH0cxdgSX7rbdCggR7IwoULD/hcLFu1apV+//33qqr6888/6+GHH65bt25VVdX//Oc/euihh+r06dN19erVe2/bt28PMOKDt3nz5lwfj9fXLrsZM1SrVNmpoNqggerPPwcdUeS0b99eU1NTgw4joiZOVK1SRRVUjzlG9b//nRF0SFGVlpYWdAhRlej7B3yr+eTHcE7yrACyd7o4HDsqzp7cN6tqeujnCUCyiFQLY90JJXv3rpSUlL3du1SVgQMHsm7dOtq2bUvNmjX33qZPnx5s0G4/rX57h3G9BtKwoV0uSU21WapcbFGFxx+HM8+EjRuhSxeY0/8dmi0eH3RozhVKOIn5G+AYETlSREoBPYCx2RcQkRoSuogqIi1D610X6WDjyXfffbe3e5eIsGnTply/GZ122mlBh+pyeuEF/jblPWbOtNmG0tOtDuGee7xTWKxIT4fLL7fiLlXo39/qRcq99gK1x47NfwXOxbB8E7Oq7gZuBj4FFgGjVHWBiFwvIteHFrsQmC8iPwCDgB6hQ/Ziad26dVx33XXevSvOVa5s8/M+9pgVAz7yiI1/XrMm6MiKtzlzrGnIm29CuXLW7/qRR7zIyyWOfIdLwd7T0xNyPDY0289DgCGRDS0+7enedeutt3r3rgSQlAR33gktW8K559o0kqmpVsXdqVPQ0RUvqtZGtV8/mxmqfn374uRNQ1yi8e+YEaTZunddcsklQYfjIqhjR+sQ1q6d9V4+/XS49VbYsSPoyIqH9evhggugTx9LytddB3PnelJ2ickTcwRl797Vtm1b796VYGrVgrQ0m6EqKQmeftoSw9y5QUeW2D76CI45xrqyVaoEo0bB0KFQtmzQkTkXHWGdynbhyd69a8uWLVSsWDHgiNxBee89FkyfTttcnipZ0mao6tYNzjsPfv0VWrSwZH3XXZCcXOTRJqwNG+Daa9nbxSs11ZLzkUfm8Ut5vHbOxQs/YnYup2rVyKhcOc9FWra0oVTXXWenVu+7zxL0rFlFFGOC++gj+NvfLCknJ8NTT1mXvzyTMoT12jkX6zwxO5fTiBHU+OSTfBcrX95OqU6caFMKzp1rU0j26eNzPB+s336zIrvu3WH1amjTBubPh1tugVwaze0vzNfOuVjmidm5nAr44X766bBwoSVkEZvZ6JhjYORI8HlJwrNjB9x/v/XA//BDu348cCBMm2aPhc0Ts0sAnpidi4By5eCZZ+C772xSlT/+gJ497Yjvq6+Cji52qdp140aN7Np9RoZN07hkiU0mEtZRsnMJxhOzcxHUtKnN8fzKK1Cjhl1zbtsWevSAn38OOrrYMnmyfXE5/3wromvUCCZNgrffhtq1g47OueDEbGIuxo3D4pa/ZqZECbjySjvqu+MOKF0a3nnHTm9feSUsXRp0hMGaPRs6d7ax4TNnQkqKnW2YM8cec664i8nEnJyczPbt24MOwxXQ9u3bSfbxQntVqGCTLCxZYkfMIjBihF0z7dHDqrqLC1X44gtLvC1awKefWvHc/ffDL7/Y9Xl/6zhnYjIxV69enZUrV7Jt2zY/CosDqsq2bdtYuXIl1atXDzqcwpswgbmPPRax1dWpA2+9ZYn4yivtsXfegYYNoUMHq+pO1Lf57t3WEKRRI2thOnkylCoFt90Gy5bBAw/YF5iIifBr51wQYrLBSKVKlQBYtWoVGRkZAUdzcHbs2EGZMmWCDiNqcu5fcnIyhx122N7XLq6VK0dWFF67o4+2a8/33muTLowYAVOm2K1OHSt26tXLJs+Id7/8AsOHwwsv2JSMYPt1xx1www1QtWqUNhyl1865ohSTiRksOcfzh/zkyZNp1qxZ0GFETULv3/PPU2vxYjucjYIjj4SXXrLk/NJLMGQILF8O//qXHUmefro1Lunc2Y4u48WWLTZv9ZAh+1aiH320TTzxj38UQRvNKL92zhWFmE3MzgVm1Ciq7znMi6KUFLj7bjtS/uADO7pMS4MJE+xWrhxceqnNBX3aaXZNNtZs2GBdut57z2LeM191yZJwySXWUrNdO7u+XiSK6LVzLprCSswi0hl4FigBDFfVx3I8L6HnuwDbgCtU9bsIx+pcQkpOhosustvy5XY9esQIm81q+HC7lSxpyfmss+xg8Pjjgxnju2MHzJgBn30GU6fakXH2JiqtWsHll8Nll0XxdLVzCS7fxCwiJYDngNOBFcA3IjJWVRdmW+ws4JjQrRXwQuhf51wB1Klj12HvuMNafH74oRVPzZ9vlcyffmrLlStnyfn0063K+dhj7ZRxJCubd+2yjmbff29DmaZPh3nz7PE9RODEE62o7dxzoWbNyG3fueIqnCPmlsBSVf0FQETeBs4Bsifmc4DX1UqoZ4hIFRGpqaqrIx6xc8VEkyZ2u/deWLPGkvKYMZYkf/3VmpdknzSjRAk47DDrPJaSYkmyRg2oXt2mSyxZ0gqxtm4tyddfw9atdl14z23lSlvv6tV2tL5u3V+npnPGdcopcMYZcPLJUKVKEf2HOFdMhJOYawPLs91fwf5Hw7ktUxs4YGJevnw5HRK4QGPjxo1USeBPrITevzlz2L17NyVj9P1Zt64l3M2b7bZpE+zcabdVq+x2YHMAOOmkDmFtq2xZKFPGkm+FClCxoh2Vz5tntyefLOTORFqMv3aRkNB/eyT+/oUjnMScW9lGzlGX4SyDiPQGeofu7pwyZcr8MLYfr6oBfwYdRBQl/v5NmZKo+1cNwtu37dvttmFDtEOKqER+7aA4/O0l9v41zG+BcBLzCqBOtvuHAzm/k4ezDKo6DBgGICLfqmqLMLYfl3z/4lsi718i7xv4/sW74rB/+S0TTuevb4BjRORIESkF9ADG5lhmLNBLTGtgk19fds455wou3yNmVd0tIjcDn2LDpV5R1QUicn3o+aHABGyo1FJsuNSV0QvZOeecS1xhjWNW1QlY8s3+2NBsPytwUwG3PayAy8cb37/4lsj7l8j7Br5/8a7Y75/4JBHOOedc7IjJ2aWcc8654iomErOI9BMRFZFqQccSSSLykIjMFZE5IjJRRGoFHVMkicgTIvJjaB/HiEiVoGOKFBG5SEQWiEiWiCRMhaiIdBaRn0RkqYjcFXQ8kSQir4jIGhFJyGGYIlJHRNJEZFHovdkn6JgiRUTKiMgsEfkhtG8Dgo4pGkSkhIh8LyLj8lou8MQsInWwdp//CzqWKHhCVZuoalNgHHBfwPFE2mfA8araBFgM9A84nkiaD5wPTA06kEjJ1l73LKARcImINAo2qogaAXQOOogo2g3cpqrHAa2BmxLo9dsJnKqqqUBToHNohE+i6QMsym+hwBMz8DRwB7k0JIl3qro5293yJNg+qupEVd0dujsDG7+eEFR1kar+FHQcEba3va6q7gL2tNdNCKo6FVgfdBzRoqqr90wOpKpbsA/42sFGFRlq0kN3k0O3hPq8FJHDga7A8PyWDTQxi0h3YKWq/hBkHNEkIg+LyHLgMhLviDm7q4CPgw7C5elArXNdnBGRekAzYGbAoURM6DTvHGAN8JmqJsy+hTyDHYRm5bNc9OdjFpHPgRq5PHUPcDdwRrRjiKa89k9VP1TVe4B7RKQ/cDNwf5EGWEj57V9omXuw02xvFGVshRXOviWYsFrnutgmIhWA0UDfHGfl4pqqZgJNQ7UqY0TkeFVNiHoBEekGrFHV2SLSIb/lo56YVbVTbo+LSGPgSOAHm86Zw4HvRKSlqv4e7bgi5UD7l4s3gfHEWWLOb/9E5B9AN+A0jbOxdwV47RJFWK1zXewSkWQsKb+hqu8HHU80qOpGEZmM1QskRGIG2gLdRaQLUAaoJCIjVfXy3BYO7FS2qs5T1eqqWk9V62EfGifEU1LOj4gck+1ud+DHoGKJBhHpDNwJdFfVbUHH4/IVTntdF6PEjmBeBhap6lNBxxNJIpKyZ1SHiJQFOpFAn5eq2l9VDw/luh7ApAMlZYiN4q9E9piIzBeRudgp+4QZ3hAyBKgIfBYaEjY0v1+IFyJynoisANoA40Xk06BjKqxQod6e9rqLgFGquiDYqCJHRN4CvgYaisgKEbk66JgirC3QEzg19Pc2J3QElghqAmmhz8pvsGvMeQ4pSmTe+cs555yLIX7E7JxzzsUQT8zOOedcDPHE7JxzzsUQT8zOOedcDPHE7JxzzsUQT8zOOedcDPHE7JxzzsUQT8zOFSMiMilbc4odInJR0DE55/blDUacK4ZE5AagI3BJaPIA51yMiPokFs652CIivYCzgAs8KTsXezwxO1eMhE5dXwaco6oZQcfjnNufJ2bnionQnLA3At1UdUfQ8TjncufXmJ0rJkRkHbAe2Bp6aLCqvhxgSM65XHhids4552KID5dyzjnnYognZueccy6GeGJ2zjnnYognZueccy6GeGJ2zjnnYognZueccy6GeGJ2zjnnYognZueccy6G/D+vaJVW+DRvCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.5918 - mae: 0.9568 - val_loss: 0.2602 - val_mae: 0.5581\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2131 - mae: 0.5077 - val_loss: 0.2061 - val_mae: 0.4892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f1149ed88>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Modelas that contain Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.1812 - mae: 0.4896 - val_loss: 0.1767 - val_mae: 0.4775\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1787 - mae: 0.4823 - val_loss: 0.1731 - val_mae: 0.4703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f11db1d48>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to avoid to define the threshold value when load a already computed model with a costumized loss fuction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config, \"threshold\":self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom activation functions\n",
    "- Custom Glorot initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev = stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01*weights))\n",
    "\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 1.5542 - mae: 0.8962 - val_loss: 1.4154 - val_mae: 0.5607\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5943 - mae: 0.5256 - val_loss: 1.4399 - val_mae: 0.5137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f1342d848>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 1.5901 - mae: 0.8871 - val_loss: 1.4671 - val_mae: 0.5719\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6168 - mae: 0.5327 - val_loss: 1.3017 - val_mae: 0.5177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f137bee08>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 1ms/step - loss: 2.0982 - huber_fn: 0.4776\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6052 - huber_fn: 0.2130: 0s - loss: 0.6364 - huber_fn: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f14e3e908>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the batch size (not the sum of weights, so the batch loss is not the weighted mean of the losses).\n",
    "- the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.9166667>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0| / 2) + (2 * |9.25 - 5| - 2 / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2377 - huber_metric: 0.1930\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2279 - huber_metric: 0.1868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f16eae748>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2151 - huber_metric: 0.1775\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2126 - huber_metric: 0.1758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f184cfe88>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.17577797>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))\n",
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.0631 - val_loss: 0.4457\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4562 - val_loss: 0.3798\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.3548\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3464\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3708 - val_loss: 0.3449\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3586341142654419"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name = \"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer = \"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_ouput_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shpe.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config, \"units\":self.units,\n",
    "               \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 1.7899 - val_loss: 0.7606\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6140 - val_loss: 0.5473\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5253510475158691"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a layer with a different behavior during training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 2.3857 - val_loss: 7.6082\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0571 - val_loss: 4.4597\n",
      "162/162 [==============================] - 0s 997us/step - loss: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7559615969657898"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Gradients w/ Autdoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3* w1**2 + 2*w1*w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=105.0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # works now!\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Training Loops - Computing Gradients using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size = 32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 6500/10000 [===>..]'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_bar(6500, 10000, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - loss: 1.2371 - mean_absolute_error: 0.5722\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - loss: 0.6774 - mean_absolute_error: 0.5280\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - loss: 0.6351 - mean_absolute_error: 0.5177\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - loss: 0.6384 - mean_absolute_error: 0.5181\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - loss: 0.6440 - mean_absolute_error: 0.5222\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables) #Compute the Gradient in regard to each trainable variable\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables)) #Gradient Descent Step\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizer_v2.nadam.Nadam at 0x23f166c1708>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Functions:\n",
    "- When you want to boost a python function just transform it into TF Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x23f168fdb88>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))\n",
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x23f168fdb88>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex12:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) define two variables weights alpha and beta, shapes [-1,:] data type tf.float32 alpha = 1, beta=0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self, alpha = 1.0, beta=0.0, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1:], self.alpha], initializer=\"ones\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[batch_input_shape[-1:], self.beta], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b)call method mean of std of each instance feature, tf.nn.moments(inputs, axes=-1, keepdims=True), returns mean and std**2 then retunr alphaX(X-mean)/(std-e) + Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(\n",
    "            name=\"kernel\", shape=batch_input_shape[-1:], initializer=\"ones\")\n",
    "        self.beta = self.add_weight(\n",
    "            name=\"bias\", shape=batch_input_shape[-1:], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, X):\n",
    "        mean, var = tf.nn.moments(X[i], axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean)/(tf.sqrt(var)+self.eps) + self.beta\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        bae_config = super().get_config()\n",
    "        return{**kwargs, \"eps\":self.eps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c) ensures that this new layer produces almost the same result as normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.22886726>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = MyLayer()\n",
    "keras_layer_norm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.18172204>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All epochs:   0%|                                                                                | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 1/5:   0%|                                                                              | 0/1718 [00:00<?, ?it/s]\u001b[A\n",
      "All epochs:   0%|                                                                                | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OrderedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17004/792606331.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                         \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mmean_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mstatus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OrderedDict' is not defined"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (localEnv2)",
   "language": "python",
   "name": "localenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
